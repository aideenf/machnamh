{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T08:15:19.167375Z",
     "start_time": "2020-09-01T08:15:17.570133Z"
    }
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import os\n",
    "import sys\n",
    "from datetime import date\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "from collections import Counter, namedtuple\n",
    "import gc\n",
    "import threading\n",
    "import time\n",
    "from itertools import cycle, chain, combinations\n",
    "import itertools\n",
    "import warnings\n",
    "import kaleido \n",
    "from contextlib import suppress\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_validate\n",
    " \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#import pprint\n",
    "import pandas_profiling\n",
    "from pandas_profiling.config import config\n",
    "from pandas_profiling.model.base import Variable\n",
    "import phik\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Button, Box\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "#from plotly.graph_objs import graph_objs as go \n",
    "\n",
    "\n",
    "\n",
    "import ipyfilechooser\n",
    "from ipyfilechooser import FileChooser\n",
    "import dill\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import shap\n",
    "\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "import benfordslaw as bl\n",
    "import missingno as msno\n",
    "\n",
    "class helper_methods():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.text_color = \"green\"\n",
    "        get_ipython().run_cell_magic('javascript', '', 'IPython.OutputArea.prototype._should_scroll = function(lines) {\\n    return false;\\n}')\n",
    "        \n",
    "    \n",
    "    \n",
    "        self.worldview = \"\"\"\n",
    "                            <b>Worldview:</b> In the context of this framework a \"Worldview\" is a set of assumptions about a\n",
    "                            physical and social reality pertaining to a human feature or attribute, or to the measurement of same. \n",
    "                            As context must be taken into consideration there is no one fundamentally correct worldview but rather \n",
    "                            a reflection of a particular philosophy of life, or a conception of the world, as it relates to each of an\n",
    "                            individuals' apparently quantifiable features or attributes. In the case of this framework, the focus is, in particular, on the worldview\n",
    "                            held concerning any disparities in features or attributes that might be detected across groups within protected\n",
    "                            features such as race, gender, age etc.\n",
    "                            A disparity may, for example, refer to a non-proportionate representation or a significant difference in \n",
    "                            distribution. <br><br>\n",
    "                            Two worldviews have been defined for this purpose: <br>\n",
    "                        \"\"\"\n",
    "        \n",
    "        self.worldview_biological = \"\"\"\n",
    "                        \n",
    "                        <b>Inherent or biological worldview: </b>This worldview postulates that either chance or innate, \n",
    "                        inherent physiological, biochemical, neurological, cultural and/or genetic factors influence any\n",
    "                        disparities in features or attributes that might be detected across groups (categorised by race, gender,\n",
    "                        age etc).\n",
    "\n",
    "                        This worldview could be quite easily applied to the measurements of weight, height, BMI or similar easily\n",
    "                        quantifiable features to be used as predictors for a specific outcome. The worldview, however, becomes \n",
    "                        more complex for those human attributes or features which are harder to quantify, such as grit, determination,\n",
    "                        intelligence, cognitive ability, self-control, growth mindset, reasoning, imagination, reliability etc. \n",
    "\n",
    "                        This Inherent or biological worldview is closely aligned with the concept of <b>individual fairness</b>,\n",
    "                        where the fairness goal is to ensure that people who are ‘similar’ concerning a combination of the specific\n",
    "                        observable and measurable features or attributes deemed relevant to the task or capabilities at hand, \n",
    "                        should receive close or similar rankings and therefor achieve similar outcomes.  \n",
    "\n",
    "                        With this worldview, observable and measurable features are considered to be inherently objective\n",
    "                        with no adjustments deemed necessary albeit with the knowledge that the human attributes or features\n",
    "                        considered critical to success may have been identified as such by the dominant group. Notwithstanding \n",
    "                        that a significant amount of the measurements used to gauge and/or measure these human features or attributes\n",
    "                        have been conceptualised, created or implemented by that same dominant group or that those historic \n",
    "                        outcomes may also have been influenced by prejudice towards a protected groups, or via favouritism \n",
    "                        towards the dominant group. \n",
    "\n",
    "                        This worldview might lead one to accept the idea that race, gender or class gaps are due to group \n",
    "                        shortcomings, not structural or systemic ones, and therefore the outcome “is what it is”, such that\n",
    "                        individuals should be ranked with no consideration to differences in outcome across groups.\n",
    "\n",
    "                        According to this worldview structural inequalities often perpetuated byracism, sexism and other prejudices \n",
    "                        <b>are not considered</b> to have any causal influence on outcomes.  \n",
    "\n",
    "                        This worldview may also lead one to believe that representation of certain groups in specific fields\n",
    "                        (such as STEM) are disproportionate to the representation in the population due to inherently different\n",
    "                        preferences and/or abilities as opposed to the influence of social factors such as the exclusion, \n",
    "                        marginalisation, and undermining of the potential of the underrepresented group or to the favouritism \n",
    "                        (manifested through cognitive biases such as similarity bias etc) shown to other members of the dominant group.\n",
    "                        This worldview might lead one to conclude that certain groups of individuals do not avoid careers in certain \n",
    "                        sectors due to lack of mentorship or the existence of (or the perception of the existence of)an exclusionary\n",
    "                        workplace culture but rather because of their individual and inherent characteristics. \n",
    "\n",
    "                        \"\"\"\n",
    "        \n",
    "        self.worldview_social = \"\"\"\n",
    "                        <b>Social and environmental worldview: </b> This worldview postulates that  social\n",
    "                        and environmental factors, such as family income, parental educational backgrounds,\n",
    "                        school, peer group, workplace, community, environmental availability of nutrition, \n",
    "                        correct environment for sleep, stereotype threat(and other cognitive biases ) \n",
    "                        often perpetuated by racism, sexism and other prejudices have influenced outcomes \n",
    "                        in terms of any detected disparities across groups. Differences in outcome may be \n",
    "                        a reflection of inequalities in a society which has led to these \n",
    "                        outcome. Identifying this has important\n",
    "                        implications for the financial, professional, and social futures of particular \n",
    "                        protected groups within the population. Discrimination, privilege, institutional \n",
    "                        racism , sexism, ablism are examples of causal influences which may impact outcomes\n",
    "                        or representation. Disparities may have been caused by intentional,explicit \n",
    "                        discrimination against a protected group or by subtle, unconscious, \n",
    "                        automatic discrimination as the result of favoritism towards the reference group,\n",
    "                        or by other social and systemic factors. The term \"affirmative action\" is often \n",
    "                        used to justify the offering of opportunities to members of protected groups who \n",
    "                        do not otherwise appear to merit the opportunity. The offering of the opportunity is\n",
    "                        often based upon personal qualities that are usually hard to quantify in an entirely\n",
    "                        objective way. However it is important to note that due to social and environmental \n",
    "                        factors many measurements relating to human performance, merit, ability, etc\n",
    "                        are also not necessarily objective. \n",
    "\n",
    "                        \"\"\"\n",
    "    def display_html(self, text, color, size):\n",
    "        content = \"<\" + size + \">\"  + \"<text style='color:\" + color + \"'>\" + text + \"</text>\" + \"</\" + size + \">\" \n",
    "        display (widgets.HTML(content, layout=Layout(width='100%'))) \n",
    "    #################################################################################################\n",
    "    #  VIEW Group representation in the data and display in the output area provided\n",
    "    # \n",
    "    #################################################################################################\n",
    "    def display_group_representation(self, data_frame, protected_features_list, output_area, _w=600, _h=600):\n",
    "        try:\n",
    "\n",
    "            with  output_area:\n",
    "                clear_output(wait = True)\n",
    "                fig_wig_a, fig_wig_b = self.plot_donut(protected_features_list,\n",
    "                                                       data_frame,\n",
    "                                                       w=_w, h=_h,\n",
    "                                                       title = \"Representation of Protected group(s) in the data\");\n",
    "                    \n",
    "                    \n",
    "                accordion = widgets.Accordion(children=[fig_wig_b, fig_wig_a])\n",
    "                accordion.set_title(0, 'Tree Map View')\n",
    "                accordion.set_title(1, 'Donut View')\n",
    "                display(accordion)\n",
    "                del fig_wig_a\n",
    "                del fig_wig_b\n",
    "        except:\n",
    "            print (\"Error in display_group_representation\")\n",
    "                    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  VIEW analysis of NUMERIC features across protected groups, also used to show outcome distributio\n",
    "    #  across groups\n",
    "    #################################################################################################\n",
    "    def numeric_feature_analysis_across_groups(self, \n",
    "                                       df, \n",
    "                                       feature,\n",
    "                                       protected_attributes_list,\n",
    "                                       label_y,\n",
    "                                       group_descriptions_dict,#will remove after refactor\n",
    "                                       label_encoding_dict,#will remove after refactor\n",
    "                                       reference_groups_dict,#will remove after refactor\n",
    "                                       _w=600, _h=600,\n",
    "                                       high_range_pos = True,\n",
    "                                       feature_data_dict = None):\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        HIGH_RANGE_POSITIVE = high_range_pos\n",
    "        \n",
    "        #If any of the protected features have a description replace the entry in the data-frame\n",
    "        #with the description so it is easier to read.\n",
    "        \n",
    "      \n",
    "        \n",
    "        def show_analysis(selected_protected, label, curve_type, remove_outliers): \n",
    "            #local method \n",
    "            #plot the representation of data in the dataframe per protected group\n",
    "            if selected_protected != \"--select--\": \n",
    "                #define a progress bar thread\n",
    "                data_frame = df.copy()\n",
    "                \n",
    "                #########TO REFACTOR- OBTAINING THE ORIGINAL PROTECTED FOR ANALYSIS#########\n",
    "                \n",
    "                \n",
    "                #label_encoding_dict only used here.\n",
    "                \n",
    "                # if group_descriptions_dict.get(selected_protected, False) != False:\n",
    "                #   print(\"Descriptions have been saved for the Feature values\")\n",
    "                    \n",
    "                \n",
    "                #if label_encoding_dict.get(selected_protected, False) != False:\n",
    "                    #print(\"Feature has been label encoded. view with pre-encoded values?\")\n",
    "                \n",
    "                #if selected_protected+\"_bm\" in data_frame.columns:\n",
    "                    #print (\"feature has had values merged, view analysis with pre-merged valies?\")\n",
    "                \n",
    "                if feature_data_dict == None: #refactor to only use a feature_data_dict\n",
    "                    for feat in protected_attributes_list:\n",
    "                        #get_feature_info returns _choice_dict_for_drop, original_values, label_encoded_values, descriptions\n",
    "                        mapping = self.get_feature_info(feat, \n",
    "                                                data_frame[feat].dropna().unique(), \n",
    "                                                group_descriptions_dict,\n",
    "                                                label_encoding_dict,\n",
    "                                                {},\n",
    "                                                {})[0]\n",
    "                        keys = list( mapping.keys())\n",
    "                        values = list (mapping.values())\n",
    "                        reverse_mapping = dict(zip(values, keys))\n",
    "                        data_frame[feat] = data_frame[feat].map(reverse_mapping)###\n",
    "                        #now the dataframe has the description.\n",
    "                \n",
    "                elif feature_data_dict != None:#HERE we will keep this after refactoring\n",
    "                    mapped_cols_df = self.map_values (data_frame, \n",
    "                                                      protected_attributes_list,\n",
    "                                                      feature_data_dict)\n",
    "                    #swap original cols with mapped cols...\n",
    "                    for feat in protected_attributes_list:\n",
    "                        data_frame[feat] = mapped_cols_df[feat]\n",
    "                \n",
    "                \n",
    "                #########END TO REFACTOR-OBTAINING THE ORIGINAL PROTECTED FOR ANALYSIS END#########\n",
    "                \n",
    "                \n",
    "                #data_frame[feat] now contains the values in the way we want to analyse.\n",
    "                #ie merged, not-merged, encoded or not, with descriptions or not.\n",
    "                \n",
    "                progress = widgets.FloatProgress(value=0.0, \n",
    "                                                 min=0.0, \n",
    "                                                 max=1.0)\n",
    "                progress.layout.width = '100%'\n",
    "                finished = False\n",
    "                def work(progress):\n",
    "                    total = 200\n",
    "                    for i in range(total):\n",
    "                        if finished != True:\n",
    "                            time.sleep(0.2)\n",
    "                            progress.value = float(i+1)/total\n",
    "                        else:\n",
    "                            progress.value = 200\n",
    "                            progress.style.bar_color = \"green\"\n",
    "                            break\n",
    "\n",
    "                thread = threading.Thread(target=work, args=(progress,))\n",
    "                display(progress)\n",
    "                #start the progress bar thread\n",
    "                thread.start()\n",
    "                #If a description was saved, use the desc rather than the actual values\n",
    "                #to achieve this we change the contents of the column to reflect the\n",
    "                #description, not the value.\n",
    "\n",
    "                \n",
    "                groups = data_frame[selected_protected].dropna().unique()\n",
    "                \n",
    "                tab = widgets.Tab()\n",
    "                widget_html_arr = []\n",
    "                tab_titles = []\n",
    "                for group in groups:\n",
    "                    filtered = data_frame[data_frame[selected_protected]==group]\n",
    "                    \n",
    "                    html_summary, outliers = self.detect_outlier_and_describe(filtered[feature],\n",
    "                                                                              3, \n",
    "                                                                              data_type = \"numeric\")\n",
    "                    \n",
    "                    widget_html_arr.append(widgets.HTML(html_summary))\n",
    "                    tab_titles.append(str(group))\n",
    "                    if remove_outliers == True:\n",
    "                        for val in outliers:\n",
    "                            indexNames = data_frame[ (data_frame[selected_protected] == group) & (data_frame[feature] == val) ].index\n",
    "                            data_frame.drop(indexNames , inplace=True) \n",
    "                tab.children = widget_html_arr\n",
    "                for x in range(len(tab_titles)):\n",
    "                    tab.set_title(x, tab_titles[x])\n",
    "\n",
    "                if curve_type == \"normal\":       \n",
    "                    text = ''' <b>Normal distribution:</b> A parametric approach which represents the behavior of most of the situations in \n",
    "                                   the universe. It's characterised by a bell shaped. The diameter, weight, strength, \n",
    "                                   and many other characteristics of natural, human or machine-made items are normally distributed.\n",
    "                                   In humans, performance, outcomes, grade point averages etc. are all normally distributed. \n",
    "                                   The normal distribution really is a normal occurrence. If we compare the normal distribution\n",
    "                                   of training data outcomes across two groups we can preform statistical test (such as the one below)\n",
    "                                   to determine if there is a <b>significant variance</b> between groups'''\n",
    "\n",
    "\n",
    "                if curve_type == \"kde\":         \n",
    "                    text = ''' <b>Kernel Density estimate:</b> is a nonparametric approach. Parametric estimation requires a \n",
    "                                    parametric family of distributions to be assumed(e.g Normal distribution). \n",
    "                                    If you have a basis to believe the model is approxiamtely correct it is advantageous to do parametric \n",
    "                                    inference. On the other hand it is possible that the data does not fit well to any member of the family.\n",
    "                                    In that case it is better to use kernel density estimation because it will construct a density that \n",
    "                                    reasonably fit the data. It does not require any assumption regarding parametric families.'''\n",
    "\n",
    "\n",
    "                fig_wig_dist, dist_output_per_group, groups = self.plot_distribution(selected_protected,\n",
    "                                                                                     feature, \n",
    "                                                                                     data_frame, \n",
    "                                                                                     w=_w, h=_h, \n",
    "                                                                                     y_high_positive = HIGH_RANGE_POSITIVE,\n",
    "                                                                                     curve_type = curve_type)\n",
    "                distOut = widgets.Output(layout={})\n",
    "                with distOut:\n",
    "                    display(fig_wig_dist)#as this returns an array of widgets\n",
    "                    display(HTML(\"\"\"Interactive version available <a href=\"output_dist.html\" target=\"_blank\"> here</a>\"\"\"))\n",
    "                    self.display_html(text, \"grey\", \"p\")\n",
    "                \n",
    "                #########TO REFACTOR- OBTAINING THE Priviliged/Reference group#########\n",
    "                #reference_groups_dict and group_descriptions_dict only used here\n",
    "                #reference_group for t_test is the actual value in the dataframe (not the description)\n",
    "                reference_group_to_use = ''\n",
    "                if feature_data_dict == None:\n",
    "                    reference_group = reference_groups_dict[selected_protected]\n",
    "                    #Now if there is a description we should convert to the description\n",
    "                    try:\n",
    "                        reference_group_to_use = group_descriptions_dict [selected_protected][reference_group]\n",
    "                    except:\n",
    "                        reference_group_to_use = reference_group  \n",
    "                else:\n",
    "                    if feature_data_dict != None: #Here, keep this one after refactoring\n",
    "                        reference_group_to_use = feature_data_dict[selected_protected]['privileged_description']\n",
    "                        if reference_group_to_use == '':\n",
    "                            reference_group_to_use = feature_data_dict[selected_protected]['original_privileged'] \n",
    "                        #'label_enc_privileged'\n",
    "                #########TO REFACTOR END#########\n",
    "                \n",
    "                #Now add the two tailed T-test*************\n",
    "                t_testOut = widgets.Output(layout={})\n",
    "                with t_testOut:\n",
    "                    clear_output(wait = True)\n",
    "                    self.get_t_test_info(dist_output_per_group, groups, reference_group_to_use) \n",
    "\n",
    "                #Now add correlation matrix*************\n",
    "                correlationOut = widgets.Output(layout={})               \n",
    "                with correlationOut:\n",
    "                    clear_output(wait = True)\n",
    "                    \n",
    "                    self.feature_analysis_plot_correlation(data_frame[[feature]+[selected_protected]+[label_y]],\n",
    "                                                           label_y,\n",
    "                                                           feature,\n",
    "                                                           selected_protected)\n",
    "                    \n",
    "\n",
    "                #Now add scatter plot*************\n",
    "                scatterPlotOut = widgets.Output(layout={})                        \n",
    "                if label_y != feature:\n",
    "                    with scatterPlotOut:\n",
    "                        tab_scat = widgets.Tab()\n",
    "                        clear_output(wait = True)\n",
    "                        wig1 = go.FigureWidget(px.scatter_3d(data_frame[[feature]+[selected_protected]+[label_y]], x=label_y, y=feature, z=selected_protected,\n",
    "                                        color=selected_protected,\n",
    "                                        width=600, height=600,\n",
    "                                        title=label_y+\" \"+feature+ \" \" + selected_protected))\n",
    "        \n",
    "\n",
    "                        wig2 = go.FigureWidget(px.scatter(data_frame[[feature]+[selected_protected]+[label_y]], x=label_y, y=feature, \n",
    "                                     color=selected_protected,\n",
    "                                     width=600, height=600,\n",
    "                                     title=label_y+\" \"+feature))\n",
    "    \n",
    "                        \n",
    "                        tab_scat.children = [wig1,wig2]\n",
    "                        tab_scat.set_title(0, \"3D view\")\n",
    "                        tab_scat.set_title(1, \"2D view\")\n",
    "                        display(tab_scat)\n",
    "                          \n",
    "                BenfordsLawOut = widgets.Output(layout={}) \n",
    "                with BenfordsLawOut:\n",
    "                    benHTML = widgets.HTML(\"\"\"\n",
    "                    Also known as the Law of First Digits or the Phenomenon of Significant Digits, \n",
    "                    this law is the finding that the first numerals of the numbers found in series\n",
    "                    of records of the most varied sources do not display a uniform distribution,\n",
    "                    but rather are arranged in such a way that the digit “1” is the most frequent,\n",
    "                    followed by “2”, “3”...in a successively decreasing manner down to “9”. This\n",
    "                    can be a useful way of analysing data for fraud detection for example. \n",
    "                    <br><b>Note:</b> The law is not applicable to all numeric series but rather to those:<br>\n",
    "                    <b>*</b> With a high order of magnitude.<br>\n",
    "                    <b>*</b> No pre-established min or max <br>\n",
    "                    <b>*</b> Not numbers used as identifiers, e.g social security, identity, bank acc.<br>\n",
    "                    <b>*</b> Have a mean which is less than the median.<br>\n",
    "                    <b>*</b> Data is not concentrated around the mean.<br>\n",
    "                    \"\"\")\n",
    "                    display(benHTML)\n",
    "                    display (self.Benfords_law(data_frame[[feature]+[selected_protected]+[label_y]], \n",
    "                                               feature, \n",
    "                                               selected_protected))\n",
    "                    \n",
    "                if label_y != feature:\n",
    "                    accordion = widgets.Accordion(children=[distOut,\n",
    "                                                        tab,\n",
    "                                                        t_testOut,\n",
    "                                                        correlationOut,\n",
    "                                                        scatterPlotOut,\n",
    "                                                        BenfordsLawOut])\n",
    "                    accordion.set_title(0, 'Distribution of ' + feature + ' grouped by '+selected_protected)\n",
    "                    accordion.set_title(1, 'Describe (min/max/mean/outliers) for  ' + feature + ' grouped by '+selected_protected)\n",
    "                    accordion.set_title(2, 'Two tailed T-test for ' + feature + ' based on ' + selected_protected)\n",
    "                    accordion.set_title(3, 'Correlation between ' + feature + \", \" + label_y + ' and '+ selected_protected)\n",
    "                    accordion.set_title(4, 'Scatter plot ' + feature + ' and ' + label_y)\n",
    "                    accordion.set_title(5, 'Benfords_law for ' + feature + ' based on ' + selected_protected )\n",
    "                    accordion.selected_index=0 \n",
    "                    \n",
    "                if label_y == feature:\n",
    "                    accordion = widgets.Accordion(children=[distOut,\n",
    "                                                        tab,\n",
    "                                                        t_testOut,\n",
    "                                                        correlationOut,\n",
    "                                                        BenfordsLawOut])\n",
    "                    accordion.set_title(0, 'Distribution of ' + feature + ' grouped by '+selected_protected)\n",
    "                    accordion.set_title(1, 'Describe (min/max/mean/outliers) for  ' + feature + ' grouped by '+selected_protected)\n",
    "                    accordion.set_title(2, 'Two tailed T-test for ' + feature + ' based on ' + selected_protected)\n",
    "                    accordion.set_title(3, 'Correlation between ' + feature + ' and '+ selected_protected)\n",
    "                    accordion.set_title(4,'Newcomb/Benford law for ' + feature + ' based on ' + selected_protected )\n",
    "                    accordion.selected_index=0  \n",
    "                display (accordion)\n",
    "                finished = True\n",
    "                del data_frame\n",
    "        \n",
    "                \n",
    "        if feature == label_y:\n",
    "            self.display_html(\"Analysis of the distribution of the target (\"+ feature + \") across groups\", \"black\", \"h4\")\n",
    "        else:\n",
    "            display(HTML(\"<h4>Select the protected feature:</h4> \"))\n",
    "            \n",
    "  \n",
    "        interact(show_analysis, \n",
    "                     selected_protected = widgets.Dropdown(description = \"Protected Feature\",\n",
    "                                                options = [\"--select--\"] + protected_attributes_list,\n",
    "                                                layout = local_layout,\n",
    "                                                style = local_style),\n",
    "                    label = widgets.HTML(description=f\"<b><font color='black'>{'Density estimation configuration :'}</b>\",\n",
    "                                         style = {'description_width': 'initial'},\n",
    "                                         layout=Layout(width='90%')\n",
    "                                        ),\n",
    "                    curve_type = widgets.Dropdown(description = \"Density Estimation\",\n",
    "                                                  options = {\"Normal Distribution\":\"normal\", \"Kernel Density Estimation\":\"kde\"},\n",
    "                                                  layout = local_layout,\n",
    "                                                  style = local_style),\n",
    "                    remove_outliers = widgets.Checkbox(value=False,\n",
    "                                                       description='Remove outliers (per group) for analysis',\n",
    "                                                       disabled=False,\n",
    "                                                       layout = local_layout,\n",
    "                                                       style = local_style,\n",
    "                                                       indent=False),\n",
    "                                                );\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  VIEW analysis of CATEGORIC features across protected groups, also used to show outcome distributio\n",
    "    #  across groups\n",
    "    #################################################################################################\n",
    "    def categoric_feature_analysis_across_groups(self, \n",
    "                                       df, \n",
    "                                       feature,\n",
    "                                       protected_attributes_list,\n",
    "                                       label_y,\n",
    "                                       group_descriptions_dict,\n",
    "                                       encoding_dict,\n",
    "                                       reference_groups_dict,\n",
    "                                       _w=600, _h=600,\n",
    "                                       high_range_pos = True):\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        HIGH_RANGE_POSITIVE = high_range_pos\n",
    "        \n",
    "        \n",
    "        \n",
    "        def show_analysis(selected_protected): #local method\n",
    "            #choose is the protected attribute we will analyze against\n",
    "            if selected_protected != \"--select--\":\n",
    "                #If a description was saved, use the desc rather than the actual values\n",
    "                #to achieve this we change the contents of the column to reflect the\n",
    "                #description, not the value.\n",
    "                data_frame = df.copy()\n",
    "                for feat in protected_attributes_list:\n",
    "                    \n",
    "                    mapping = self.get_feature_info(feat, \n",
    "                                    data_frame[feat].dropna().unique(), \n",
    "                                    group_descriptions_dict,\n",
    "                                    encoding_dict,\n",
    "                                        {},{})[0]\n",
    "                    keys = list( mapping.keys())\n",
    "                    values = list (mapping.values())\n",
    "                    reverse_mapping = dict(zip(values, keys))\n",
    "                    data_frame[feat] = data_frame[feat].map(reverse_mapping)\n",
    "                    \n",
    "                ####\n",
    "                #set up a threaded progress bar\n",
    "                progress = widgets.FloatProgress(value=0.0, min=0.0, max=1.0)\n",
    "                progress.layout.width = '100%'\n",
    "                finished = False\n",
    "                def work(progress):\n",
    "                    total = 200\n",
    "                    for i in range(total):\n",
    "                        if finished != True:\n",
    "                            time.sleep(0.2)\n",
    "                            progress.value = float(i+1)/total\n",
    "                        else:\n",
    "                            progress.value = 200\n",
    "                            progress.style.bar_color = \"green\"\n",
    "                            break\n",
    "\n",
    "                thread = threading.Thread(target=work, args=(progress,))\n",
    "                display(progress)\n",
    "                #start the progress bar\n",
    "                thread.start()\n",
    "\n",
    "                groups = data_frame[selected_protected].dropna().unique()\n",
    "                output_values = data_frame[feature].dropna().unique()\n",
    "                layout = go.Layout(xaxis=dict(type='category'))\n",
    "                fig_hist_count = go.FigureWidget(layout=layout)  \n",
    "                fig_hist_percent = go.FigureWidget(layout=layout)\n",
    "                with fig_hist_count.batch_update():\n",
    "                    for group in groups:\n",
    "                        temp = data_frame[[selected_protected, feature]].fillna(\"@Unknown\")\n",
    "                        temp = temp[temp[selected_protected]==group]\n",
    "                        if feature == label_y:\n",
    "                            if high_range_pos == True:\n",
    "                                temp.loc[(temp[feature] == 1)] = \"1(Positive impact)\"\n",
    "                                temp.loc[(temp[feature] == 0)] = \"0(Negative impact)\"\n",
    "                                \n",
    "                            elif high_range_pos == False:\n",
    "                                temp.loc[(temp[feature] == 0)] = \"0(Positive impact)\"\n",
    "                                temp.loc[(temp[feature] == 1)] = \"1(Negative impact)\"\n",
    "\n",
    "                        fig_hist_count.add_trace(go.Histogram(\n",
    "                                                    x=temp[feature],\n",
    "                                                    name = selected_protected +\":\"+group,\n",
    "                                                    histfunc=\"count\",\n",
    "                                                    opacity=0.75))\n",
    "        \n",
    "                        fig_hist_percent.add_trace(go.Histogram(\n",
    "                                                    x=temp[feature],\n",
    "                                                    name = selected_protected +\":\"+group,\n",
    "                                                    histnorm = 'percent',\n",
    "                                                    opacity=0.75))\n",
    "                        \n",
    "                    fig_hist_count.update_layout(\n",
    "                                        title_text='Count across groups', # title of plot\n",
    "                                        xaxis_title_text=feature, # xaxis label\n",
    "                                        yaxis_title_text='Count', # yaxis label\n",
    "                                        bargap = 0.2, # gap between bars of adjacent location coordinates\n",
    "                                        bargroupgap = 0.1, # gap between bars of the same location coordinates\n",
    "                                        legend_title = selected_protected,\n",
    "                                        autosize = False\n",
    "                                        )\n",
    "                    fig_hist_percent.update_layout(\n",
    "                                        title_text='Percentage across groups', # title of plot\n",
    "                                        xaxis_title_text = selected_protected, # xaxis label\n",
    "                                        yaxis_title_text='Percent', # yaxis label\n",
    "                                        bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "                                        bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "                                        legend_title = selected_protected,\n",
    "                                        autosize=False\n",
    "                                        )\n",
    "                \n",
    "                \n",
    "                ####get information about each group, such as the count, num unique values.\n",
    "                describe_tab = widgets.Tab()\n",
    "                widget_html_arr = []\n",
    "                tab_titles = []\n",
    "                for group in groups:\n",
    "                    filtered = data_frame[data_frame[selected_protected]==group]\n",
    "                    html_summary = self.detect_outlier_and_describe(filtered[feature], \n",
    "                                                                    3, \n",
    "                                                                    data_type = \"categoric\")[0]\n",
    "\n",
    "                    widget_html_arr.append(widgets.HTML(html_summary))\n",
    "                    tab_titles.append(str(group))\n",
    "                describe_tab.children = widget_html_arr\n",
    "                for x in range(len(tab_titles)):\n",
    "                    describe_tab.set_title(x, tab_titles[x])\n",
    "                histOut = widgets.Output(layout={})\n",
    "                with histOut:\n",
    "                    hist_tab = widgets.Tab()\n",
    "                    hist_tab.children = [fig_hist_count,fig_hist_percent]\n",
    "                    hist_tab.set_title(0, \"Count\")\n",
    "                    hist_tab.set_title(1, \"Percentage\")\n",
    "                    display(hist_tab)\n",
    "                       \n",
    "                describeOut = widgets.Output(layout={})\n",
    "                with describeOut:\n",
    "                    display(describe_tab)\n",
    "                \n",
    "                sigOut = widgets.Output(layout={})\n",
    "                with sigOut:\n",
    "                    #reference_group for t_test is the actual value in the dataframe (not the description)\n",
    "                    reference_group = reference_groups_dict[selected_protected]\n",
    "                    #Now if there is a description we should convert to the description\n",
    "                    try:\n",
    "                        reference_group_to_use = group_descriptions_dict [selected_protected][reference_group]\n",
    "                    except:\n",
    "                        reference_group_to_use = reference_group \n",
    "                        \n",
    "                    self.get_chi_square_test_info(data_frame[[feature]+[selected_protected]], \n",
    "                                                   feature, \n",
    "                                                   selected_protected, \n",
    "                                                   reference_group_to_use) \n",
    " \n",
    "                    \n",
    "                correlationOut = widgets.Output(layout={})\n",
    "                with correlationOut:\n",
    "                    self.feature_analysis_plot_correlation(data_frame[[feature]+[selected_protected]+[label_y]],\n",
    "                                                           label_y,feature,\n",
    "                                                           selected_protected)\n",
    "                    \n",
    "                \n",
    "                accordion = widgets.Accordion(children=[histOut,\n",
    "                                                        describeOut,\n",
    "                                                        sigOut,\n",
    "                                                        correlationOut,\n",
    "                                                        ])\n",
    "                accordion.set_title(0, 'Count of ' + feature + ' grouped by '+ selected_protected)\n",
    "                accordion.set_title(1, 'Describe ' + feature + ' grouped by '+ selected_protected)\n",
    "                accordion.set_title(2, 'Pearson’s chi-squared significance test  ' + feature + ' based on ' + selected_protected)\n",
    "                accordion.set_title(3, 'Correlation between ' + feature + \", \" + label_y + ' and '+ selected_protected)\n",
    "                accordion.selected_index=0 \n",
    "                display(accordion)\n",
    "                #end the progress bar thread\n",
    "                finished = True\n",
    "                del data_frame\n",
    "\n",
    "        if feature == label_y:\n",
    "            self.display_html(\"Analysis of the distribution of the target (\"+ feature + \") across groups.\", \"black\", \"h4\")\n",
    "        else:\n",
    "            self.display_html(\"Analysis of input feature: \"+ feature + \" across groups.\", \"black\", \"h4\")\n",
    "            \n",
    "        \n",
    "        interact(show_analysis, \n",
    "                 selected_protected = widgets.Dropdown(description = \"Protected Feature\",\n",
    "                                            options = [\"--select--\"] + protected_attributes_list,\n",
    "                                            layout = local_layout,\n",
    "                                            style = local_style),\n",
    "                )\n",
    "\n",
    "    \n",
    "    \n",
    "    ################################################################################################\n",
    "    # Correlation plot for protected group and all values\n",
    "    # \n",
    "    ################################################################################################\n",
    "    def plot_correlation_per_group(self, data_frame, protected_feature):\n",
    "        widget_dict = {}\n",
    "        plt.figure(figsize=(8, 8)) \n",
    "        for group in data_frame[protected_feature].dropna().unique():\n",
    "            print(group)\n",
    "            temp_df = data_frame[data_frame[protected_feature]== group]\n",
    "            temp_df.drop(protected_feature, axis=1, inplace = True )\n",
    "            corr = self.phi_k_correlation(temp_df)\n",
    "            corr.reset_index(drop=True, inplace=True)\n",
    "            corr[\"index\"] = pd.Series(list(corr.columns))\n",
    "            corr = corr.set_index(\"index\")\n",
    "\n",
    "            heatmap = go.FigureWidget(go.Heatmap(z=corr,\n",
    "                         zmin=0, \n",
    "                         zmax=1,\n",
    "                         x=corr.columns,\n",
    "                         y=corr.columns,\n",
    "                        xgap=1, ygap=1,\n",
    "                        colorscale= px.colors.sequential.Blues,\n",
    "                        colorbar_thickness=20,\n",
    "                        colorbar_ticklen=3))\n",
    "\n",
    "            title = 'Correlation Matrix'               \n",
    "            with heatmap.batch_update():\n",
    "                heatmap.update_layout(go.Layout(title_text=title, title_x=0.5, \n",
    "                                        width=300, height=300,\n",
    "                                        xaxis_showgrid=False,\n",
    "                                        yaxis_showgrid=False,\n",
    "                                        yaxis_autorange='reversed'\n",
    "                                        ))\n",
    "            widget_dict[group] = heatmap\n",
    "        return widget_dict\n",
    "        box = widgets.HBox(widget_dict.values)\n",
    "        display(box )\n",
    "       \n",
    "        \n",
    "    #################################################################################################\n",
    "    # Correlation plot for feature or label vs protected feature\n",
    "    # \n",
    "    ################################################################################################\n",
    "    def feature_analysis_plot_correlation(self, data_frame, label_y, feature, protected_feature):\n",
    "        #remove any duplicate column that might occur when feature is the label\n",
    "        data_frame = data_frame.loc[:,~data_frame.columns.duplicated()]\n",
    "        html = widgets.HTML(\"\"\"<b>Phik (φk)</b><br>\n",
    "                        Phik (φk) is a new and practical correlation coefficient that\n",
    "                        works consistently between categorical, ordinal and interval\n",
    "                        variables, captures non-linear dependency and reverts to \n",
    "                        the Pearson correlation coefficient in case of a bivariate \n",
    "                        normal input distribution. There is extensive documentation\n",
    "                        available here https://phik.readthedocs.io/en/latest/index.html\"\"\")\n",
    "\n",
    "        display(html)\n",
    "       \n",
    "        plt.figure(figsize=(6, 6)) \n",
    "        \n",
    "            \n",
    "        if label_y != feature:\n",
    "            corr = self.phi_k_correlation(data_frame[[feature]+[protected_feature]+[label_y]])\n",
    "            res1 = corr.loc[ feature , : ][protected_feature]\n",
    "            res2 = corr.loc[ feature , : ][label_y]\n",
    "            text = \"Correlation value for \" + feature + \" and \" + protected_feature + \" is \" + str (res1)\n",
    "            text = text + \"<br>Correlation value for \" + feature + \" and \" + label_y + \" is \" + str (res2)\n",
    "\n",
    "        elif label_y == feature:\n",
    "            corr = self.phi_k_correlation(data_frame[[label_y]+[protected_feature]])\n",
    "            res1 = corr.loc[ feature , : ][protected_feature]\n",
    "            text = \"Correlation value for \" + feature + \" and \" + protected_feature + \" is \" + str (res1)\n",
    "\n",
    "        corr.reset_index(drop=True, inplace=True)\n",
    "        corr[\"index\"] = pd.Series(list(corr.columns))\n",
    "        corr = corr.set_index(\"index\")\n",
    "\n",
    "        heatmap = go.FigureWidget(go.Heatmap(z=corr, \n",
    "                         x=corr.columns,\n",
    "                         y=corr.columns,\n",
    "                        xgap=1, ygap=1,\n",
    "                        colorscale= px.colors.sequential.Blues,\n",
    "                        colorbar_thickness=20,\n",
    "                        colorbar_ticklen=3))\n",
    "\n",
    "        title = 'Correlation Matrix'               \n",
    "        with heatmap.batch_update():\n",
    "            heatmap.update_layout(go.Layout(title_text=title, title_x=0.5, \n",
    "                                        width=300, height=300,\n",
    "                                        xaxis_showgrid=False,\n",
    "                                        yaxis_showgrid=False,\n",
    "                                        yaxis_autorange='reversed'\n",
    "                                        ))\n",
    "        display(heatmap)\n",
    "        display (HTML(text))\n",
    "      \n",
    "    #################################################################################################\n",
    "    #  VIEW Counts of categorical features or output\n",
    "    #  view_categorical_counts(data_frame, feature, high_range_pos)\n",
    "    ################################################################################################\n",
    "    def view_categorical_counts (self, data_frame, feature, high_range_pos = True ):\n",
    "        layout = go.Layout(xaxis=dict(type='category'))\n",
    "        if high_range_pos == True:\n",
    "            data_frame.loc[(data_frame[feature] == 1),feature] = \"1(Positive impact)\"\n",
    "            data_frame.loc[(data_frame[feature] == 0),feature] = \"0(Negative impact)\"\n",
    "\n",
    "        elif high_range_pos == False:\n",
    "            data_frame.loc[(data_frame[feature] == 0),feature] = \"0(Positive impact)\"\n",
    "            data_frame.loc[(data_frame[feature] == 1),feature] = \"1(Negative impact)\"\n",
    "            \n",
    "        count = go.FigureWidget(layout=layout)  \n",
    "        pcnt = go.FigureWidget(layout=layout)  \n",
    "\n",
    "        count.add_trace(go.Histogram(\n",
    "                    x=data_frame[feature],\n",
    "                    histfunc=\"count\",\n",
    "                    opacity=0.75))\n",
    "\n",
    "        pcnt.add_trace(go.Histogram(\n",
    "                     x=data_frame[feature],\n",
    "                    histnorm = 'percent',\n",
    "                    opacity=0.75))\n",
    "\n",
    "        \n",
    "\n",
    "        count.update_layout(\n",
    "                        title_text='Count of total', # title of plot\n",
    "                        xaxis_title_text=feature, # xaxis label\n",
    "                        yaxis_title_text='Count', # yaxis label\n",
    "                        bargap = 0.2, # gap between bars of adjacent location coordinates\n",
    "                        bargroupgap = 0.1, # gap between bars of the same location coordinates\n",
    "                        autosize = False\n",
    "                        )\n",
    "        pcnt.update_layout(\n",
    "                        title_text='Percent of total', # title of plot\n",
    "                        xaxis_title_text=feature, # xaxis label\n",
    "                        yaxis_title_text='Percent', # yaxis label\n",
    "                        bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "                        bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "                        autosize=False\n",
    "                        )\n",
    "        return count, pcnt\n",
    "    \n",
    "     #################################################################################################\n",
    "    #  VIEW Counts of categorical features or output\n",
    "    #  view_categorical_counts(data_frame, selected_protected, feature, high_range_pos)\n",
    "    #################################################################################################  \n",
    "    def view_categorical_counts_for_protected(self, \n",
    "                                data_frame, \n",
    "                                protected_feature,\n",
    "                                feature,\n",
    "                                label_y,\n",
    "                                high_range_pos = True):\n",
    "        \n",
    "\n",
    "        groups = data_frame[protected_feature].dropna().unique()\n",
    "        output_values = data_frame[protected_feature].dropna().unique()\n",
    "\n",
    "        \n",
    "        layout = go.Layout(xaxis=dict(type='category'))\n",
    "        fig_hist_count = go.FigureWidget(layout=layout)  \n",
    "        fig_hist_percent = go.FigureWidget(layout=layout)\n",
    "        with fig_hist_count.batch_update():\n",
    "            for group in groups:\n",
    "                temp = data_frame[[protected_feature, feature]].fillna(\"@Unknown\")\n",
    "                temp = temp[temp[protected_feature]==group]\n",
    "                if feature == label_y:\n",
    "                    if high_range_pos == True:\n",
    "                        temp.loc[(temp[feature] == 1),feature] = \"1(Positive impact)\"\n",
    "                        temp.loc[(temp[feature] == 0),feature] = \"0(Negative impact)\"\n",
    "\n",
    "                    elif high_range_pos == False:\n",
    "                        temp.loc[(temp[feature] == 0),feature] = \"0(Positive impact)\"\n",
    "                        temp.loc[(temp[feature] == 1),feature] = \"1(Negative impact)\"\n",
    "\n",
    "                fig_hist_count.add_trace(go.Histogram(\n",
    "                                            x=temp[feature],\n",
    "                                            name = protected_feature +\":\"+group,\n",
    "                                            histfunc=\"count\",\n",
    "                                            opacity=0.75))\n",
    "\n",
    "                fig_hist_percent.add_trace(go.Histogram(\n",
    "                                            x=temp[feature],\n",
    "                                            name = protected_feature +\":\"+group,\n",
    "                                            histnorm = 'percent',\n",
    "                                            opacity=0.75))\n",
    "\n",
    "            fig_hist_count.update_layout(\n",
    "                                title_text='Count across groups', # title of plot\n",
    "                                xaxis_title_text=feature, # xaxis label\n",
    "                                yaxis_title_text='Count', # yaxis label\n",
    "                                bargap = 0.2, # gap between bars of adjacent location coordinates\n",
    "                                bargroupgap = 0.1, # gap between bars of the same location coordinates\n",
    "                                legend_title = protected_feature,\n",
    "                                autosize = False\n",
    "                                )\n",
    "            fig_hist_percent.update_layout(\n",
    "                                title_text='Percentage across groups', # title of plot\n",
    "                                xaxis_title_text = feature, # xaxis label\n",
    "                                yaxis_title_text='Percent', # yaxis label\n",
    "                                bargap=0.2, # gap between bars of adjacent location coordinates\n",
    "                                bargroupgap=0.1, # gap between bars of the same location coordinates\n",
    "                                legend_title = protected_feature,\n",
    "                                autosize=False\n",
    "                                )\n",
    "\n",
    "        return fig_hist_count, fig_hist_percent\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    #################################################################################################\n",
    "    #  Convert encoded or merged features back to original values to allow for more \n",
    "    #  intuitive analysis of fairness.\n",
    "    #################################################################################################  \n",
    "    def convert_feature_column(self, \n",
    "                               df,\n",
    "                               feature,\n",
    "                               feature_data):\n",
    "        \n",
    "       # one-hot-encode (done)\n",
    "       # label_encode (done)\n",
    "       # merged (done)\n",
    "       # merged and one-hot-encode (TODO)\n",
    "       # merged and label_encode (TODO)\n",
    "        if len(feature_data['values_description']) == 0:\n",
    "            feature_data['values_description'] = feature_data['original_values']\n",
    "    \n",
    "        \n",
    "        # If the feature was one_hot_encoded but not merged, de-encode and return the original col, \n",
    "        # and original vals with description(if exists)\n",
    "        if feature_data['one_hot_enc'] == True and feature_data['values_merged'] == False:\n",
    "            df[feature] = self.de_hot_encode_feature (df, \n",
    "                                                      feature_data['one_hot_enc_col_before'], \n",
    "                                                      feature_data['one_hot_enc_cols_after'])\n",
    "            mapping_dict = dict(zip(feature_data['original_values'], \n",
    "                                    feature_data['values_description']))\n",
    "            df[feature] = df[feature].map(mapping_dict)\n",
    "            return df[feature]\n",
    "        \n",
    "        # If the feature was label encoded but not merged, return the original col, \n",
    "        # and original vals with description(if exists)\n",
    "        elif feature_data['label_enc'] == True and feature_data['values_merged'] == False:\n",
    "            \n",
    "            mapping_dict = dict(zip(feature_data['label_enc_values'], \n",
    "                                    feature_data['values_description']))\n",
    "            \n",
    "            df[feature] = df[feature].map(mapping_dict)\n",
    "            return df[feature]\n",
    "        \n",
    "        # If the feature was merged but not one-hot encoded or label encoded\n",
    "        elif feature_data['values_merged'] == True:\n",
    "            print (\"merged!\")\n",
    "            df[feature] = df[feature_data['before_merge_col']]\n",
    "            mapping_dict = dict(zip(feature_data['original_values'], \n",
    "                                    feature_data['values_description']))\n",
    "            df[feature] = df[feature].map(mapping_dict)\n",
    "            return df[feature]\n",
    "        \n",
    "    \n",
    "        else:\n",
    "            return df[feature]\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  VIEW STATISTICS AROUND. THE PROTECTED FEATURES/ATTRIBUTES\n",
    "    # \n",
    "    #################################################################################################       \n",
    "    def set_decision_boundary(self, df, data_summary):\n",
    "        #if the function was already called, remove the generated column to start again.\n",
    "        if data_summary.y_value +'_binary' in df.columns:\n",
    "            df.drop(data_summary.y_value +'_binary', axis = 1, inplace = True)\n",
    "            \n",
    "        #copy the input data_frame to avoid permanent changes as we will de-encode etc.    \n",
    "        data_frame = df.copy()\n",
    "        out1 = widgets.Output(layout={})\n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        display (out1)\n",
    "        layout = go.Layout(xaxis=dict(type='category'))\n",
    "        try:\n",
    "            with out1:\n",
    "                clear_output(wait = True)\n",
    "                self.display_html(\"Description of Target\", self.text_color, \"h3\")\n",
    "                if data_summary.Y_BINARY == True:\n",
    "                    self.display_html(\"The target is a binary value(1 or 0)\", \"black\", \"p\")\n",
    "                    if data_summary.HIGH_RANGE_POSITIVE == True:\n",
    "                        impactTxt = \"<b>Positive</b>\"\n",
    "                    if data_summary.HIGH_RANGE_POSITIVE == False:\n",
    "                        impactTxt = \"<b>Negative</b>\"\n",
    "                    x = \"An output of 1 has a <b>\" + impactTxt + \"</b> impact on an individual\" \n",
    "                    self.display_html(str(x), self.text_color, \"h4\")\n",
    "                \n",
    "                elif data_summary.Y_CONTINUOUS == True:\n",
    "                    self.display_html(\"The target is a continuous value\", \"black\", \"p\")\n",
    "                    y_Min = round(data_frame[data_summary.y_value].min(), 3)\n",
    "                    y_Mean = round(data_frame[data_summary.y_value].mean(), 3)\n",
    "                    y_Max = round(data_frame[data_summary.y_value].max(), 3)\n",
    "                    text = \"\"\n",
    "                    text = text + \"Minimum: \" + str(y_Min) + \"<br>\"\n",
    "                    text = text + \"Mean: \" +str(y_Mean)+ \"<br>\"\n",
    "                    text = text + \"Max: \" +str(y_Max)+ \"<br>\"\n",
    "                    self.display_html(text, \"black\", \"p\")\n",
    "                    if data_summary.HIGH_RANGE_POSITIVE == True:\n",
    "                        impactTxt = \"<b>Positive</b>\"\n",
    "                    if data_summary.HIGH_RANGE_POSITIVE == False:\n",
    "                        impactTxt = \"<b>Negative</b>\"\n",
    "\n",
    "                    x = \"The Impact of a high output(ranking) on an individual or group is <b>\" + impactTxt + \".</b>\"\n",
    "                    self.display_html(str(x), \"black\", \"p\")\n",
    "                    \n",
    "                    self.display_html(\"Select the decision boundary between a positive and negative outcome for logistic regression training.\", \"black\", \"h4\")\n",
    "                    text = \"\"\"Logistic regression is a predictive modelling algorithm that is used when the target (Y )\n",
    "                            is binary categorical. That is, it can take only two values e.g 1 or 0.\n",
    "                            The goal is to determine a mathematical equation that can be used to predict the probability \n",
    "                            of event 1, if you wish to use logistic regression to predict a successful outcome in terms of \"\"\" + data_summary.y_value + \"\"\", \n",
    "                            you must select a decision boundary after which the continuous value  will represent 1\"\"\"\n",
    "                    self.display_html(text, \"black\", \"p\")\n",
    "                \n",
    "                    \n",
    "                    #revert to thevalues as we wish to see them\n",
    "                   \n",
    "                    for protected_feat in data_summary.protected_before_transform:\n",
    "                        data_frame[protected_feat] = self.convert_feature_column(\n",
    "                                                                 data_frame,\n",
    "                                                                 protected_feat,\n",
    "                                                                 data_summary.feature_data_dict[protected_feat])\n",
    "                        \n",
    "                    \n",
    "                    def select_boundary(choose): #local method\n",
    "                        #plot the representation of data in the dataframe per protected group\n",
    "                        slider = widgets.IntSlider()\n",
    "                        \n",
    "                        def set_outcome (s):\n",
    "                            #data_summary.y_value\n",
    "                            if slider.description == \"Select Percentile\":\n",
    "                                try:\n",
    "                                     data_frame.drop(data_summary.y_value +'_binary', axis = 1, inplace = True)\n",
    "                                except:\n",
    "                                    pass \n",
    "    \n",
    "                                s = s/100\n",
    "                                data_frame[data_summary.y_value +'_Percentile_Rank'] = data_frame[data_summary.y_value].rank(pct = True)\n",
    "                                data_frame.loc[data_frame[data_summary.y_value +'_Percentile_Rank'] >= s, data_summary.y_value+'_binary'] = 1\n",
    "                                data_frame.loc[data_frame[data_summary.y_value +'_Percentile_Rank'] < s, data_summary.y_value+'_binary'] = 0\n",
    "                                data_frame.drop(data_summary.y_value +'_Percentile_Rank', axis = 1, inplace = True)\n",
    "                                #self.display_html(_text, self.text_color, \"p\")\n",
    "                                #total = data_frame[[data_summary.y_value, data_summary.y_value+'_binary']].groupby(data_summary.y_value+'_binary').count().reset_index()\n",
    "                                \n",
    "                                fig_widget_arr = []\n",
    "                                tab_titles = []\n",
    "                                hist_tab = widgets.Tab()\n",
    "                                \n",
    "                                count, pcnt = self.view_categorical_counts(data_frame.copy(),\n",
    "                                                                 data_summary.y_value+'_binary',\n",
    "                                                                 data_summary.HIGH_RANGE_POSITIVE)\n",
    "                                \n",
    "                                \n",
    "                                tab_titles.append(\"Total count\")\n",
    "                                fig_widget_arr.append(count)\n",
    "                                tab_titles.append(\"Total percentage\")\n",
    "                                fig_widget_arr.append(pcnt) \n",
    "                                \n",
    "                                for protected_feat in data_summary.protected_before_transform:\n",
    "                                    #protected_total = data_frame[[data_summary.y_value, data_summary.y_value+'_binary', protected_feat]].groupby([data_summary.y_value+'_binary',protected_feat]).count().reset_index()\n",
    "                                    #view_categorical_counts returns go.FigureWidget type.\n",
    "                                    count, pcnt = self.view_categorical_counts_for_protected(data_frame.copy(),\n",
    "                                                                 protected_feat, \n",
    "                                                                 data_summary.y_value+'_binary',\n",
    "                                                                 data_summary.y_value+'_binary',\n",
    "                                                                 data_summary.HIGH_RANGE_POSITIVE)\n",
    "                                    tab_titles.append(str(protected_feat) + \" count\")\n",
    "                                    fig_widget_arr.append(count)\n",
    "                                    tab_titles.append(str(protected_feat) + \" percentage\")\n",
    "                                    fig_widget_arr.append(pcnt)    \n",
    "                                hist_tab.children = fig_widget_arr\n",
    "                                for x in range(len(tab_titles)):\n",
    "                                    hist_tab.set_title(x, tab_titles[x])\n",
    "                                display(hist_tab)\n",
    "                                #Now apply the modification to the original input df\n",
    "                                df[data_summary.y_value+'_binary'] = data_frame[data_summary.y_value+'_binary']\n",
    "                        \n",
    "                            elif slider.description == \"Select n for Top_n\":\n",
    "                                try:\n",
    "                                     data_frame.drop(data_summary.y_value +'_binary', axis = 1, inplace = True)\n",
    "                                except:\n",
    "                                    pass \n",
    "                                #Ascending means smallest to largest, go from smallest to largest, take the value in position s.\n",
    "                                yDivPoint = data_frame.sort_values(data_summary.y_value,ascending = False).head(s).min()[data_summary.y_value]\n",
    "                                data_frame.loc[data_frame[data_summary.y_value ] >= yDivPoint, data_summary.y_value+'_binary'] = 1\n",
    "                                data_frame.loc[data_frame[data_summary.y_value ] < yDivPoint, data_summary.y_value+'_binary'] = 0\n",
    "                                self.display_html(\"\"\"The \"\"\" + str(s) + \"\"\"th position has value of <b>\"\"\" + str(yDivPoint) + \"\"\"</b>, any value equal to or above\n",
    "                                                   this will be set to <b>1</b>. Any value below this will be set to <b>0</b>\"\"\", \"black\", \"p\")\n",
    "\n",
    "                                fig_widget_arr = []\n",
    "                                tab_titles = []\n",
    "                                hist_tab = widgets.Tab()\n",
    "                                \n",
    "                                count, pcnt = self.view_categorical_counts(data_frame.copy(),\n",
    "                                                                 data_summary.y_value+'_binary',\n",
    "                                                                 data_summary.HIGH_RANGE_POSITIVE)\n",
    "                                \n",
    "                                \n",
    "                                tab_titles.append(\"Total count\")\n",
    "                                fig_widget_arr.append(count)\n",
    "                                tab_titles.append(\"Total percentage\")\n",
    "                                fig_widget_arr.append(pcnt) \n",
    "                                \n",
    "                                for protected_feat in data_summary.protected_before_transform:\n",
    "                                    #protected_total = data_frame[[data_summary.y_value, data_summary.y_value+'_binary', protected_feat]].groupby([data_summary.y_value+'_binary',protected_feat]).count().reset_index()\n",
    "                                    #view_categorical_counts returns go.FigureWidget type.\n",
    "                                    count, pcnt = self.view_categorical_counts_for_protected(data_frame.copy(),\n",
    "                                                                 protected_feat, \n",
    "                                                                 data_summary.y_value+'_binary',\n",
    "                                                                 data_summary.y_value+'_binary',\n",
    "                                                                 data_summary.HIGH_RANGE_POSITIVE)\n",
    "                                    tab_titles.append(str(protected_feat) + \" count\")\n",
    "                                    fig_widget_arr.append(count)\n",
    "                                    tab_titles.append(str(protected_feat) + \" percentage\")\n",
    "                                    fig_widget_arr.append(pcnt)    \n",
    "                                hist_tab.children = fig_widget_arr\n",
    "                                for x in range(len(tab_titles)):\n",
    "                                    hist_tab.set_title(x, tab_titles[x])\n",
    "                                display(hist_tab)\n",
    "                                #Now apply the modification to the original input df\n",
    "                                df[data_summary.y_value+'_binary'] = data_frame[data_summary.y_value+'_binary']\n",
    "                                \n",
    "                        if choose == \"Mean\":\n",
    "                            try:\n",
    "                                data_frame.drop(data_summary.y_value +'_binary', axis = 1, inplace = True)\n",
    "                            except:\n",
    "                                pass \n",
    "                            text = \"Values between \" + str(y_Min) + \" and \" + str(y_Mean) + \" will be converted to <b>0</b><br>\"\n",
    "                            text = text + \"Values between \" + str(y_Mean) + \" and \" + str(y_Max) + \" will be converted to <b>1</b>\"\n",
    "                            self.display_html(text, \"black\", \"p\")\n",
    "                            \n",
    "                            data_frame.loc[data_frame[data_summary.y_value] >= y_Mean, data_summary.y_value+'_binary'] = 1\n",
    "                            data_frame.loc[data_frame[data_summary.y_value] <  y_Mean, data_summary.y_value+'_binary'] = 0\n",
    "                            \n",
    "                            fig_widget_arr = []\n",
    "                            tab_titles = []\n",
    "                            hist_tab = widgets.Tab()\n",
    "\n",
    "                            count, pcnt = self.view_categorical_counts(data_frame.copy(),\n",
    "                                                             data_summary.y_value+'_binary',\n",
    "                                                             data_summary.HIGH_RANGE_POSITIVE)\n",
    "\n",
    "\n",
    "                            tab_titles.append(\"Total count\")\n",
    "                            fig_widget_arr.append(count)\n",
    "                            tab_titles.append(\"Total percentage\")\n",
    "                            fig_widget_arr.append(pcnt) \n",
    "\n",
    "                            for protected_feat in data_summary.protected_before_transform:\n",
    "                                #protected_total = data_frame[[data_summary.y_value, data_summary.y_value+'_binary', protected_feat]].groupby([data_summary.y_value+'_binary',protected_feat]).count().reset_index()\n",
    "                                #view_categorical_counts returns go.FigureWidget type.\n",
    "                               \n",
    "                                count, pcnt = self.view_categorical_counts_for_protected(data_frame.copy(),\n",
    "                                                             protected_feat, \n",
    "                                                             data_summary.y_value+'_binary',\n",
    "                                                             data_summary.y_value+'_binary',\n",
    "                                                             data_summary.HIGH_RANGE_POSITIVE)\n",
    "                                tab_titles.append(str(protected_feat) + \" count\")\n",
    "                                fig_widget_arr.append(count)\n",
    "                                tab_titles.append(str(protected_feat) + \" percentage\")\n",
    "                                fig_widget_arr.append(pcnt)    \n",
    "                            hist_tab.children = fig_widget_arr\n",
    "                            for x in range(len(tab_titles)):\n",
    "                                hist_tab.set_title(x, tab_titles[x])\n",
    "                            display(hist_tab)\n",
    "                            #Now apply the modification to the original input df\n",
    "                            df[data_summary.y_value+'_binary'] = data_frame[data_summary.y_value+'_binary']\n",
    "                              \n",
    "\n",
    "                        if choose == \"Percentile\":\n",
    "                            slider = widgets.IntSlider(\n",
    "                                    description = \"Select Percentile\", \n",
    "                                    min=0, max=100,\n",
    "                                    step=1, value=80, \n",
    "                                    continuous_update=False,\n",
    "                                    style = local_style)\n",
    "                            interact(set_outcome, s = slider)\n",
    "                            \n",
    "                        if choose == \"Top-n\":\n",
    "                            slider = widgets.IntSlider(\n",
    "                                    description = \"Select n for Top_n\", \n",
    "                                    min=10, max=1000,\n",
    "                                    step=10, value=100, \n",
    "                                    continuous_update=False,\n",
    "                                    style = local_style) \n",
    "                            interact(set_outcome, s = slider)\n",
    "                            \n",
    "                    _choose = widgets.Dropdown(\n",
    "                                    description = \"Decision boundary determined by\", \n",
    "                                    options = [\"Mean\",\"Top-n\",\"Percentile\"],\n",
    "                                    layout = local_layout,\n",
    "                                    style = local_style)\n",
    "\n",
    "                    interact(select_boundary, choose = _choose)\n",
    "                    \n",
    "\n",
    "                    change = widgets.Button(description=\"View dataframe head\")\n",
    "                    button_output = widgets.Output()\n",
    "                    def on_button_clicked(b):\n",
    "                        with button_output:\n",
    "                            clear_output(wait = True)\n",
    "                            display(df.head(5))\n",
    "                    change.on_click(on_button_clicked)\n",
    "                    display(change, button_output)\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong in method\", self.text_color, \"h4\")\n",
    "            print (e)\n",
    "        \n",
    "          \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################         \n",
    "    def create_label (self, row):\n",
    "            \n",
    "            names = list (row.index)\n",
    "            values = list( row.values)\n",
    "            text = \"\"\n",
    "            for i in range (len(names)):\n",
    "                text = text + \":\" + names[i] + \"_\" + str(values[i])\n",
    "            text = text[1:]            \n",
    "            return text       \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################       \n",
    "    def plot_donut(self, attributes_list, data_frame, w=800, h=800, title = \"Result\"):\n",
    "    \n",
    "        num_of_donuts = len(attributes_list)\n",
    "        if num_of_donuts > 6:\n",
    "            num_of_donuts = 6\n",
    "            display (HTML(\"showing only the first 6 attributes\"))\n",
    "        \n",
    "        sequential_color_list = [\n",
    "            px.colors.sequential.Blues,\n",
    "            px.colors.sequential.Greens, \n",
    "            px.colors.sequential.Oranges, \n",
    "            px.colors.sequential.Purples,\n",
    "            px.colors.sequential.Reds,\n",
    "            px.colors.sequential.Greys,\n",
    "            px.colors.sequential.algae,\n",
    "            px.colors.sequential.amp]\n",
    "    \n",
    "        color_pool = cycle(sequential_color_list)\n",
    "    \n",
    "        pie_list = []    \n",
    "        labels_arr = []\n",
    "        values_arr = []\n",
    "        color_arr = []\n",
    "        annotations_arr = []\n",
    "        annotate = dict(text='woops', \n",
    "            x=0.5, y=0.6, \n",
    "            font_size=15, \n",
    "            showarrow=False)\n",
    "        \n",
    "        attribute_hierarchy = []\n",
    "        for a, pos in zip (attributes_list, range(len(attributes_list))):\n",
    "            attribute_hierarchy.append(a)\n",
    "            annotate['text'] = a\n",
    "            annotate['y'] = annotate['y']-0.05\n",
    "            annotations_arr.append(annotate.copy())\n",
    "            data_frame[\"count\"] = 0\n",
    "            df = data_frame[attribute_hierarchy+[\"count\"]].fillna(\"@Unknown\").groupby(attribute_hierarchy).count().reset_index().rename(columns={\"count\": \"values\"})\n",
    "            df['labels'] =  df.apply(lambda row : self.create_label(row[attribute_hierarchy]), axis = 1) \n",
    "            df['values'].fillna(0,inplace=True)\n",
    "            c = []\n",
    "            s = []\n",
    "            if pos == 0:\n",
    "                for l in range (len(df['labels'].to_numpy())):\n",
    "                    c.append(next(color_pool)[0])\n",
    "                    if l >= len(sequential_color_list):\n",
    "                        l = l - len(sequential_color_list)\n",
    "                    s.append(l)\n",
    "                df['colors'] = c\n",
    "                df['color_pool_pos'] = s\n",
    "                \n",
    "            else:\n",
    "                temp_list = list(df['values'].to_numpy())#changed from .list\n",
    "                for count, color_index in zip(prev_counts, prev_color_pool) :\n",
    "                    match = 0\n",
    "                    for value, pos in zip (temp_list, range(len(temp_list))):\n",
    "                        s.append(color_index)\n",
    "                        try:\n",
    "                            c.append (sequential_color_list[color_index][pos+1])\n",
    "                        except:\n",
    "                            c.append (sequential_color_list[color_index][2])\n",
    "                        match = match + value\n",
    "                        if match == count:\n",
    "                            del temp_list[0:pos+1]\n",
    "                            break\n",
    "                df['colors'] = c\n",
    "                df['color_pool_pos'] = s\n",
    "            labels_arr.append (df['labels'])\n",
    "            values_arr.append (df['values'])\n",
    "            color_arr.append (df['colors'])\n",
    "        \n",
    "            prev_counts = df['values'].values\n",
    "            prev_color_pool = df['color_pool_pos'].values\n",
    "        hole = 0.8\n",
    "        x1 = 0\n",
    "        x2 =1\n",
    "        y1 = 0\n",
    "        y2 = 1\n",
    "        adjust = round((1.0 - hole)* 0.5,2) \n",
    "        for x in range (num_of_donuts):\n",
    "            pie_list.append(go.Pie(\n",
    "            hole=hole, #Sets the fraction of the radius to cut out of the pie. Use this to make a donut chart\n",
    "            sort=False,\n",
    "            direction='clockwise',\n",
    "            domain={'x': [x1, x2], 'y': [y1, y2]},\n",
    "            values=values_arr[x],\n",
    "            labels=labels_arr[x],\n",
    "            textinfo='label+percent',\n",
    "            textposition='inside',\n",
    "            name=attributes_list[x],\n",
    "            marker={'colors': color_arr[x],'line': {'color': 'black', 'width': 1}}\n",
    "            ))\n",
    "            hole= round(hole - adjust, 2)\n",
    "            x1 = round (x1 + adjust, 2)\n",
    "            x2 = round (x2 - adjust, 2)\n",
    "            y1 = round (y1 + adjust, 2)\n",
    "            y2 = round (y2 - adjust, 2)\n",
    "         \n",
    "        \n",
    "        fig = go.FigureWidget(data=pie_list);#need to reverse the order?\n",
    "        fig.update_layout(autosize=False,\n",
    "                          width=w,\n",
    "                          height=h,\n",
    "                          margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "                          title=str(attribute_hierarchy),\n",
    "                          #Add annotations in the center of the donut pies.\n",
    "                          annotations=annotations_arr,\n",
    "                          legend_orientation=\"h\",\n",
    "                           #paper_bgcolor='rgba(113, 136, 136, 1)', #for transparent set to (0,0,0,0)\n",
    "                          #plot_bgcolor='rgba(113, 136, 136, 1)',\n",
    "                    );\n",
    "\n",
    "        fig.update_traces(textposition='inside');\n",
    "        fig.update(layout_title_text=title,\n",
    "               layout_showlegend=False );\n",
    "        df[\"all\"] = \"all\"\n",
    "        fig_2 = px.treemap(df, \n",
    "                           path=[\"all\"]+attributes_list, \n",
    "                           values='values',  \n",
    "                          )\n",
    "        \n",
    "        fig_2.data[0].textinfo = 'current path+ label+value+percent parent+percent root'\n",
    "         # # # # # Now create one donut per protected attribute for a clearer view if the call specifies this# # # # # # \n",
    "        fig_2.update(layout_title_text=title,\n",
    "               layout_showlegend=True );\n",
    "        fig_wig_2 = go.FigureWidget(fig_2);\n",
    "\n",
    "        #as this can be a pointer to the input, clean it up\n",
    "        data_frame.drop([\"count\"], axis=1, inplace = True)\n",
    "        gc.collect()\n",
    "        return fig, fig_wig_2\n",
    "        \n",
    "    #################################################################################################\n",
    "    # Pearson’s Chi-Squared Test....\n",
    "    # METHOD USED TO Perform Independent chi_square_test. can be used as a test for independance\n",
    "    # between categorical variables\n",
    "    #################################################################################################\n",
    "    #################################################################################################\n",
    "    def get_chi_square_test_info(self, df, feature, protected_feature, ref_group): \n",
    "        '''A categorical variable is a variable that may take on one of a set of labels.\n",
    "           Here we will examine a categorical variable as they pertain to another categorical label, \n",
    "           specifically a protected feature such as Gender(Male, Female), or Race(Black, White)\n",
    "           as it pertains to another variable such as Score, Success etc,\n",
    "            Large values of X^2 indicate that observed and expected frequencies are far apart. \n",
    "            Small values of X^2 indicate that observed are close to expecteds.\n",
    "            X^2 give a measure of the distance between observed and expected frequencies.\n",
    "            expected frequency is that there will be no difference between observed and expected\n",
    "            above what would be expected by chance (no statistically significant difference)'''\n",
    "        try:\n",
    "            groups = df[protected_feature].dropna().unique()\n",
    "            table = pd.crosstab(df[protected_feature], df[feature])\n",
    "            prob = 0.95\n",
    "            \n",
    "\n",
    "            #can be used to create multiple plots, however we only call it with attribute_list of len 1.            \n",
    "            def test_res(group_1, group_2):\n",
    "                filter_table  = table[table.index.isin([group_1,group_2])]\n",
    "                for col in filter_table.columns:\n",
    "                    if filter_table[col].sum() == 0:\n",
    "                        filter_table.drop(col, inplace=True)\n",
    "                chi2_stat, p_value, dof, expected = chi2_contingency(filter_table)\n",
    "                ######\n",
    "                #Interprert the critical value\n",
    "                # critical = chi2.ppf(prob, dof)\n",
    "                #print (\"critical(chi2.ppf(prob, dof)): \", critical)\n",
    "                #if abs(chi2_stat) >= critical:\n",
    "                     #print('Dependent (reject H0)')\n",
    "                #else:\n",
    "                   #print('Independent (fail to reject H0)')\n",
    "                #######\n",
    "\n",
    "                # interpret p-value for consistency with other test\n",
    "                     #alpha = 1.0 - prob\n",
    "                    #print('significance=%.3f, p=%.3f' % (alpha, p_value))\n",
    "\n",
    "                     #if  p_value <= alpha:\n",
    "                     #    print('Dependent (reject H0)')\n",
    "                     #else:\n",
    "                     #    print('Independent (fail to reject H0)')\n",
    "\n",
    "                ####\n",
    "\n",
    "                matrix_twosample = [\n",
    "                                    ['', 'Chi-2 Test Statistic(T-Value)', 'P-value'],\n",
    "                                    ['Sample Data', abs(chi2_stat), p_value]\n",
    "                                    ]\n",
    "\n",
    "                wig2 = go.FigureWidget(ff.create_table(matrix_twosample, index=True))\n",
    "                display (wig2)\n",
    "                text = \"There is a \"+ str (round ((p_value*100),3)) +  \"% probability that a difference of \" + str(chi2_stat)\n",
    "                text = text + \"\"\" occured by chance. A usual interpretation is that a p-value of less than 0.05 (5% probability)\n",
    "                is deemed to indicate that the difference has not occured by chance (rejecting H0)\"\"\"\n",
    "\n",
    "                self.display_html(text, self.text_color, \"p\")\n",
    "\n",
    "            self.display_html(\"Chi-Squared T-Test \", \"black\", \"h3\")\n",
    "            text = ''' <b>Significant variance:</b> The statistic test will tell us if there is a significant difference in the \n",
    "                        distribution of categories, if this difference is due to chance, or how likely it is that it is not due to chance but\n",
    "                        rather to an unobserved factor. <br>\n",
    "\n",
    "\n",
    "                        <b>T-Value:</b>This value represents the distance between the observed distribution\n",
    "                        and the expected distribution in a fair world. \n",
    "                        The larger the value of T, the greater the evidence against the difference\n",
    "                        occuring by chance in a fair world. <br>'''\n",
    "            self.display_html(text, \"black\", \"p\")\n",
    "\n",
    "            interact(test_res, \n",
    "                        group_1 = widgets.Dropdown(description = \"Reference Group\", \n",
    "                                                   options =  groups, \n",
    "                                                   value = ref_group,\n",
    "                                                   style = {'description_width': 'initial'}),\n",
    "                        group_2 = widgets.Dropdown(description = \"Focal Group\", \n",
    "                                                   options =  groups)\n",
    "                );\n",
    "\n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong generating the distribution, change the distribution type and ensure group is represented sufficiently to generate dist\", \n",
    "                              self.text_color, \"h4\")\n",
    "            print (e)  \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # METHOD USED TO Perform Independent t-Test. A t-test is a type of inferential statistic which is used to\n",
    "    # determine if there is a significant difference between the means of two groups which may be \n",
    "    # related in certain features\n",
    "    #################################################################################################\n",
    "    def get_t_test_info(self, dist_output_per_group, groups, ref_group):\n",
    "        try:\n",
    "            #can be used to create multiple plots, however we only call it with attribute_list of len 1.            \n",
    "            def test_res(group_1, group_2):\n",
    "                group_index_1 = list(groups).index(group_1)\n",
    "                group_index_2 = list(groups).index(group_2)\n",
    "\n",
    "                twosample_results = stats.ttest_ind(dist_output_per_group[group_index_1],  dist_output_per_group[group_index_2])\n",
    "                matrix_twosample = [\n",
    "                                    ['', 'Test Statistic(T-Value)', 'P-value'],\n",
    "                                    ['Sample Data', twosample_results[0], twosample_results[1]]\n",
    "                                    ]\n",
    "\n",
    "                wig2 = go.FigureWidget(ff.create_table(matrix_twosample, index=True))\n",
    "                display (wig2)\n",
    "                text = \"There is a \"+ str (round ((twosample_results[1]*100),3)) +  \"% probability that a difference of \" +str(twosample_results[0]) +\" occured by chance.\"\n",
    "                self.display_html(text, self.text_color, \"p\")\n",
    "           \n",
    "            self.display_html(\"Two-Tailed T-Test \", \"black\", \"h3\")\n",
    "            text = ''' <b>Significant variance:</b> The statistic test will tell us if there is a significant variance in the distribution \n",
    "                        and if this variance is due to chance, or how likely it is that it is not due to chance but\n",
    "                        rather to an unobserved factor. <br>\n",
    "                        \n",
    "                        \n",
    "                        <b>T-Value:</b>This value represents the distance between the observed distribution\n",
    "                        and the expected distribution in a fair world. \n",
    "                        The larger the value of T, the greater the evidence against the difference\n",
    "                        occuring by chance in a fair world. <br>'''\n",
    "            \n",
    "            self.display_html(text, \"black\", \"p\")    \n",
    "            interact(test_res, \n",
    "                        group_1 = widgets.Dropdown(description = \"Reference Group\", \n",
    "                                                   options =  groups, \n",
    "                                                   value = ref_group,\n",
    "                                                   style = {'description_width': 'initial'}),\n",
    "                        group_2 = widgets.Dropdown(description = \"Focal Group\", \n",
    "                                                   options =  groups)\n",
    "                );\n",
    "                 \n",
    "                            \n",
    "\n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong generating the distribution, change the distribution type and ensure group is represented sufficiently to generate dist\", \n",
    "                              self.text_color, \"h4\")\n",
    "            print (e)\n",
    "\n",
    "           \n",
    "        \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # METHOD USED TO PLOT THE DISTRIBUTION OF THE OUTCOME ACROSS GROUPS\n",
    "    #################################################################################################\n",
    "    \n",
    "    def plot_distribution(self, \n",
    "                          attribute, \n",
    "                          y, \n",
    "                          data_frame, \n",
    "                          w=800, h=800, \n",
    "                          y_high_positive = True, \n",
    "                          curve_type = \"kde\"):\n",
    "        try:\n",
    "            #can be used to creatr multiple plots, however we only call it with attribute_list of len 1.\n",
    "            dist_output_per_group = []\n",
    "            group_labels = []\n",
    "            groups = data_frame[attribute].dropna().unique()\n",
    "            #For every group in the protected feature\n",
    "            \n",
    "            \n",
    "            for group in range(len(groups)):\n",
    "                group_df = data_frame[data_frame[attribute] == groups[group]]\n",
    "                dist_output_per_group.append(group_df[y])\n",
    "                group_labels.append(attribute + \"-\" + str(groups[group]))\n",
    "                # Add histogram data\n",
    "                # Group data together\n",
    "                \n",
    "            #Add the dist of all combined groups\n",
    "            dist_output_per_group.append(data_frame[y])\n",
    "            group_labels.append(\"All\")\n",
    "            \n",
    "            # Create distplot with custom bin_size\n",
    "            \n",
    "            # Add title\n",
    "            \n",
    "            wig = go.Figure(ff.create_distplot(dist_output_per_group, \n",
    "                                           group_labels, \n",
    "                                           curve_type = curve_type, \n",
    "                                           show_hist=False) )#, bin_size=[.1, .25, .5, 1])\n",
    "    \n",
    "            with wig.batch_update():\n",
    "                wig.update_layout(autosize=False,\n",
    "                              width=900,\n",
    "                              height=500,\n",
    "                              #margin=dict(l=50,r=50,b=100, t=100,pad=4),\n",
    "                              #paper_bgcolor=\"LightSteelBlue\",\n",
    "                              title=y +' distribution across ' + attribute,\n",
    "                              xaxis=dict(range=[data_frame[y].min(), data_frame[y].max()])\n",
    "                            )\n",
    "            \n",
    "            img_bytes = wig.to_image(format=\"png\", engine=\"kaleido\")\n",
    "            wig.write_html(\"output_dist.html\")\n",
    "\n",
    "            image_wig = widgets.Image(value=img_bytes,\n",
    "                                   format='png',\n",
    "                                   width=800,\n",
    "                                   height=500)\n",
    "            \n",
    "\n",
    "            del wig\n",
    "            return image_wig, dist_output_per_group, groups\n",
    "\n",
    "        except Exception as e:\n",
    "            self.display_html(\"Something went wrong generating the distribution, change the distribution type and ensure group is represented sufficiently to generate dist\", \n",
    "                              self.text_color, \"h4\")\n",
    "            print (e)\n",
    "\n",
    "        \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  #NOT FULLY IMPLEMENTED\n",
    "    # \n",
    "    #################################################################################################\n",
    "    def plot_output_ratios( ):\n",
    "        sequential_color_list = [\n",
    "            px.colors.sequential.Greens, \n",
    "            px.colors.sequential.Greys]\n",
    "\n",
    "        df_ratios = data_frame[attributes_list+[impact_col_name]+[y_value]].groupby(attributes_list+[impact_col_name]).count().reset_index().rename(columns={y_value: \"values\"})     \n",
    "        \n",
    "        _total =  df_ratios['values'].sum()\n",
    "        _total_pos =  df_ratios[(df_ratios[impact_col_name]==\"Pos\")]['values'].sum()\n",
    "        _total_neg =  df_ratios[(df_ratios[impact_col_name]==\"Neg\")]['values'].sum()\n",
    "        one, isto = self.ratio(_total_pos, _total_neg)\n",
    "        df_ratios['labels'] =  df_ratios.apply(lambda row : self.create_label(row[attributes_list]), axis = 1) \n",
    "        df_ratios['labels'].fillna(0,inplace=True)\n",
    "        attr_list = []\n",
    "        attr_list.append(\"All\")\n",
    "        isto_list = []\n",
    "        isto_list.append(isto)\n",
    "        pcnt_list = []\n",
    "        pcnt_list.append((_total_pos/(_total_pos+_total_neg))*100)\n",
    "        for label in df_ratios['labels'].dropna().unique():\n",
    "            pos = df_ratios[(df_ratios['labels']==label) & (df_ratios[impact_col_name]==\"Pos\")]['values']\n",
    "            neg = df_ratios[(df_ratios['labels']==label) & (df_ratios[impact_col_name]==\"Neg\")]['values']\n",
    "            one, isto = self.ratio(pos.values[0], neg.values[0])\n",
    "            attr_list.append(label)\n",
    "            isto_list.append(isto)\n",
    "            pcnt = (pos.values[0]/(pos.values[0]+neg.values[0]))*100\n",
    "            if math.isnan(pcnt):\n",
    "                pcnt_list.append(0)\n",
    "            else:\n",
    "                pcnt_list.append(pcnt)\n",
    "        \n",
    "        fig1 = go.Figure()\n",
    "        fig1.add_trace(go.Bar(\n",
    "                            x=attr_list,\n",
    "                            y=isto_list,\n",
    "                            marker_color='indianred'\n",
    "                        ))\n",
    "\n",
    "\n",
    "            # Here we modify the tickangle of the xaxis, resulting in rotated labels.\n",
    "        fig1.update_layout(xaxis_tickangle=-45, \n",
    "                           title = \"Ratio of Positive to Negative (for each 1 positive effect)\",\n",
    "                          autosize=False,\n",
    "                          width=900,\n",
    "                          height=400,)\n",
    "        \n",
    "        fw = go.FigureWidget(fig1)\n",
    "    \n",
    "\n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    ################################################################################################# \n",
    "    def label_encoding(self, attributes_list, data_frame):\n",
    "        # creating initial dataframe\n",
    "        labelencoder = LabelEncoder()\n",
    "        return_dict = {}\n",
    "        for attribute in attributes_list:\n",
    "            categories = data_frame[attribute].dropna().unique()\n",
    "            temp_df = pd.DataFrame(categories, columns=[attribute])\n",
    "            # Assigning numerical values and storing in another column\n",
    "            temp_df[attribute+\"_benc\"] = temp_df[attribute]\n",
    "            temp_df[attribute] = labelencoder.fit_transform(temp_df[attribute])\n",
    "            # Convert this Temp_df into a dictionary\n",
    "            temp_df.set_index(attribute+\"_benc\", inplace=True)\n",
    "            return_dict.update(temp_df.to_dict())\n",
    "            data_frame[attribute+\"_benc\"] = data_frame[attribute]\n",
    "            data_frame[attribute] = labelencoder.fit_transform(data_frame[attribute])\n",
    "        return return_dict\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################   \n",
    "    def gcd(self, p, q): \n",
    "        if (q == 0): \n",
    "            return p\n",
    "        else:\n",
    "            return min(q, p)\n",
    "\n",
    "    def ratio(self, a,b):\n",
    "        _gcd = self.gcd(a,b)\n",
    "        one = round(a/_gcd, 2)\n",
    "        isto = round(b/_gcd, 2)\n",
    "        if one != 1:\n",
    "            isto = round (1/one, 2)\n",
    "            one = 1.0\n",
    "        return one, isto\n",
    "\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  VIEW FAIRNESS MATRICS AEQUITAS\n",
    "    # \n",
    "    #################################################################################################\n",
    "    \"\"\"Difference in means: The difference between the probability for a member of group-a be selected and \n",
    "        the probability for a member of group-b to be selected.\n",
    "\n",
    "        Disparate Impact: the Probability of a member of group-a be selected to be selected divided by\n",
    "        the probability of a member of group-b to be selected\n",
    "\n",
    "        False positive rate Ratio of false positive ratio's among protected groups\n",
    "\n",
    "       False negative rate: Ratio of false negative ratio's among protected groups\"\"\"\n",
    "            \n",
    "    def view_aequitas_fairness_metrics(self, \n",
    "                                       X_df, \n",
    "                                       y_target, \n",
    "                                       y_pred,\n",
    "                                       data_summary):\n",
    "        #copying it here so we do not make any modifications to the original\n",
    "        X_data_frame = X_df.copy()\n",
    "        y_column_name = y_target.name\n",
    "        _w=600\n",
    "        _h=600\n",
    "        protected_attributes_list = data_summary.protected_before_transform\n",
    "        feature_data_dict = data_summary.feature_data_dict\n",
    "        y_high_positive = data_summary.HIGH_RANGE_POSITIVE\n",
    "        aeq_Plot = Plot()\n",
    "        aeq_Group = Group()\n",
    "        aeq_Bias = Bias()\n",
    "        aeq_Fairness = Fairness()\n",
    "\n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        out5 = widgets.Output(layout={})\n",
    "        out6 = widgets.Output(layout={})\n",
    "        out7 = widgets.Output(layout={})\n",
    "        tab_contents = [out1, out2, out3, out4, out5, out6,out7]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab(style={'description_layout':'auto', 'title_layout':'auto'})\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Confusion Matrix\")\n",
    "        tab.set_title(1, \"False Positive\")\n",
    "        tab.set_title(2, \"False Negative\")\n",
    "        tab.set_title(3, \"All Metrics\")\n",
    "        tab.set_title(4, \"Disparate Impact\")\n",
    "        tab.set_title(5, \"Fairness\")\n",
    "        tab.set_title(6, \"Metrics reminder\")\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        \n",
    "        #Convert the protected feature columns back to their values\n",
    "        #before label encoding or one-hot encoding\n",
    "        for feature in protected_attributes_list:\n",
    "            X_data_frame[feature] = self.convert_feature_column(X_data_frame,\n",
    "                                        feature,\n",
    "                                        feature_data_dict[feature])\n",
    "        \n",
    "        _choose_a = widgets.Dropdown(description = \"Select protected feature\", \n",
    "                                     options = protected_attributes_list,\n",
    "                                     layout = local_layout,\n",
    "                                     style = local_style)\n",
    "          \n",
    "        _choose_b = widgets.Dropdown(description = \"Select protected group\", \n",
    "                                             options = X_data_frame[_choose_a.value].dropna().unique(),\n",
    "                                             layout = local_layout,\n",
    "                                             style = local_style)\n",
    "        \n",
    "        _choose_measure = widgets.Dropdown(description = \"Select metric\", \n",
    "                                             options = {'False Omission Rate' : 'for',\n",
    "                                                        'False Discovery Rate' :'fdr',\n",
    "                                                        'False Positive Rate': 'fpr',\n",
    "                                                        'False Negative Rate': 'fnr',\n",
    "                                                        'Negative Predictive Value': 'npv',\n",
    "                                                        'Precision': 'precision',\n",
    "                                                        'Predicted Positive Ratio_k' :'ppr',\n",
    "                                                        'Predicted Positive Ratio_g': 'pprev',\n",
    "                                                        'Group Prevalence':'prev'},\n",
    "                                             layout = local_layout,\n",
    "                                             value = 'precision',\n",
    "                                             style = local_style)\n",
    "    \n",
    "        \n",
    "        _choose_disparity_measure = widgets.Dropdown(description = \"Select disparity metric\", \n",
    "                                             options = {'False Positive Rate disparity': 'fpr_disparity',\n",
    "                                                        'False Negative Rate disparity': 'fnr_disparity',\n",
    "                                                        'Predicted Positive Ratio_k' : 'ppr_disparity',\n",
    "                                                        'Predicted Positive Ratio_g disparity' :'pprev_disparity',\n",
    "                                                        'Precision Disparity': 'precision_disparity',\n",
    "                                                        'False Discovery Rate disparity': 'fdr_disparity',\n",
    "                                                        'False Omission Rate disparity': 'for_disparity',\n",
    "                                                        'True Positive Rate disparity': 'tpr_disparity',\n",
    "                                                        'True Negative Rate disparity': 'tnr_disparity',\n",
    "                                                        'npv_disparity': 'npv_disparity',},\n",
    "                                             layout = local_layout,\n",
    "                                             value = 'fpr_disparity',\n",
    "                                             style = local_style)\n",
    "        \n",
    "        html = '''<h3>Aequitas fairness via Machnamh: </h3> Aequitas is an open source bias audit toolkit for\n",
    "        machine learning developers, analysts, and  policymakers to audit machine learning models for discrimination\n",
    "        and bias, and make informed and equitable decisions around developing and deploying predictive risk-assessment \n",
    "        tools.<br>The Machnamh framework provides a dynamic interface to Aequitas API allowing for quick analysis and a useful\n",
    "        user interface to help facilitate the translation of results'''\n",
    "        display (HTML(html))\n",
    "        display(tab)\n",
    "        \n",
    "        df_aequitas = pd.concat([X_data_frame[protected_attributes_list],\n",
    "                                        y_target,\n",
    "                                        pd.DataFrame(y_pred, \n",
    "                                        index=X_data_frame.index)],\n",
    "                                        axis=1, sort=False);\n",
    "        \n",
    "    \n",
    "        #Aequitas needs the true-y_value column to be called 'label_value'\n",
    "        # and the prediction to be called 'scire'\n",
    "        df_aequitas.rename(columns={y_column_name: 'label_value',\n",
    "                                    0: 'score'}, \n",
    "                           inplace=True);\n",
    "        \n",
    "        df_aequitas[df_aequitas.columns.difference(['label_value', 'score'])] = df_aequitas[\n",
    "                                                    df_aequitas.columns.difference(['label_value', 'score'])].astype(str);\n",
    "                \n",
    "        \n",
    "        cross_tab, _ =  aeq_Group.get_crosstabs(df_aequitas)\n",
    "        cross_tab.fillna(0, inplace = True)\n",
    "        absolute_metrics = aeq_Group.list_absolute_metrics(cross_tab) \n",
    "        #columns not in absolute Matrix\n",
    "        counts_metrics = list (cross_tab[[col for col in cross_tab.columns if col not in absolute_metrics]].columns.values)\n",
    "        counts_metrics.remove('model_id') \n",
    "        counts_metrics.remove('score_threshold') \n",
    "        counts_metrics.remove('k') \n",
    "        \n",
    "        ## Read images from file (because this is binary, maybe you can find how to use ByteIO) but this is more easy\n",
    "        path = os.path.dirname(sys.modules[__name__].__file__)\n",
    "        img2 = open(path + '/data/count.png', 'rb').read()\n",
    "        img1 = open(path + '/data/absolute.png', 'rb').read()\n",
    "        ## Create image widgets. You can use layout of ipywidgets only with widgets.\n",
    "        ## Set image variable, image format and dimension.\n",
    "        wi1 = widgets.Image(value=img1, format='png', width=300, height=400)\n",
    "        wi2 = widgets.Image(value=img2, format='png', width=300, height=400)\n",
    "        ## Side by side thanks to HBox widgets\n",
    "        sidebyside = widgets.HBox([wi1, wi2])\n",
    "        ## Finally, show.\n",
    "        \n",
    "        with out1:\n",
    "            clear_output(wait = True)\n",
    "            tab = widgets.Tab()\n",
    "            tab_names = []\n",
    "            output_arr = {}\n",
    "            for feature in protected_attributes_list:\n",
    "               \n",
    "                output_arr[feature] = widgets.Output(layout={})\n",
    "                \n",
    "                with output_arr[feature]:\n",
    "                    if  y_high_positive == True:\n",
    "                        html = \"\"\"You have indicated that a high ranking is beneficial to an individual or \n",
    "                                        group, therefor <font color='red'><b>false negatives</b></font> can be particularally harmful \n",
    "                                        in terms of fairness!\"\"\"\n",
    "\n",
    "                    \n",
    "                    elif y_high_positive == False:\n",
    "                        html = \"\"\"You have indicated that a low ranking is beneficial to an individual or \n",
    "                                        group, therefor <font color='red'><b>false positives</b></font> can \n",
    "                                        be particularally harmful in terms of fairness!\"\"\"\n",
    "                    widgHTML = widgets.GridBox(children=[widgets.HTML(html)],\n",
    "                        layout=Layout(\n",
    "                        width='90%',\n",
    "                        )\n",
    "                   )  \n",
    "                    display (widgHTML)\n",
    "                    one = widgets.Output(layout={})\n",
    "                    two = widgets.Output(layout={})\n",
    "                    three = widgets.Output(layout={})\n",
    "                    \n",
    "                    accordion1 = widgets.Accordion(children=[one, two, three])\n",
    "                    accordion1.set_title(0, \"Absolute Metrics across \" + feature  + \" groups\")  \n",
    "                    accordion1.set_title(1, \"Group counts across \" + feature + \" groups\")  \n",
    "                    accordion1.set_title(2, \"Metrics description \")  \n",
    "                    with one:\n",
    "                        included = ['attribute_name', 'attribute_value'] + absolute_metrics\n",
    "                        display ( cross_tab[included][ cross_tab[included]['attribute_name'] == feature].round(2))\n",
    "                    with two:\n",
    "                        display (cross_tab[counts_metrics][ cross_tab[counts_metrics]['attribute_name'] == feature] )\n",
    "                    with three:\n",
    "                        display(sidebyside)\n",
    "                    accordion1.selected_index = None\n",
    "                    display(accordion1)\n",
    "                    self.make_confusion_matrix(cross_tab[counts_metrics], \n",
    "                                              feature,\n",
    "                                              group_names = ['True Neg','False Pos','False Neg','True Pos'],\n",
    "                                              categories='auto',\n",
    "                                              count=True,\n",
    "                                              percent=True,\n",
    "                                              cbar=True,\n",
    "                                              xyticks=True,\n",
    "                                              xyplotlabels=True,\n",
    "                                              sum_stats=True,\n",
    "                                              figsize=(3,3),\n",
    "                                              cmap='Blues',\n",
    "                                              title=None)\n",
    "                    \n",
    "                    \n",
    "            tab.children = list(output_arr.values())\n",
    "            for i in range(len(protected_attributes_list)):\n",
    "                tab.set_title(i, protected_attributes_list[i])\n",
    "            display (tab)\n",
    "            \n",
    "        with out2: #False Positive\n",
    "            clear_output(wait = True)\n",
    "            html = \"\"\"<b>False Positive Rate:</b> The model predicted the subjects outcome \n",
    "            was positive when in fact it was not, in other words <b>an incorrect decision to \n",
    "            recommend for action!</b>\"\"\"\n",
    "\n",
    "            if  y_high_positive == True:\n",
    "                html = html + '''You have indicated that a high outcome (ranking) has a positive impact on an individual\n",
    "                                therefore a high false positive rate will have a <font color='green'><b>positive impact</b></font>  on an individual or group.\n",
    "                                '''\n",
    "            elif y_high_positive == False:\n",
    "                html = html + '''You have indicated that a high outcome (ranking) has a negative impact on an individual\n",
    "                                therefore a high false positive rate will have a <font color='red'><b>negative impact</b></font> on an individual or group.\n",
    "                                '''\n",
    "            \n",
    "            \n",
    "            \n",
    "            widgHTML = widgets.GridBox(children=[widgets.HTML(html)],\n",
    "                        layout=Layout(\n",
    "                        width='90%',\n",
    "                        )\n",
    "                   )      \n",
    "            display (widgHTML)\n",
    "            fig1, (ax1) = plt.subplots(nrows=1, figsize=(10 ,5));\n",
    "            ax1 = aeq_Plot.plot_group_metric(cross_tab,'fpr', ax1);\n",
    "            plt.tight_layout();\n",
    "            ax1.set_title('False Positive ratios');\n",
    "            plt.show();\n",
    "            plt.close(fig1);\n",
    "            plt.clf();\n",
    "        \n",
    "        \n",
    "        with out3:#False Negative\n",
    "            clear_output(wait = True)\n",
    "            html = \"\"\"<b>False Negative Rate:</b> The model predicted the subjects outcome was negative\n",
    "            when in fact it was not, in other words <b>an incorrect decision not to recommend for action!</b> \"\"\"\n",
    "            if  y_high_positive == True:\n",
    "                html = html +  '''You have indicated that a high outcome (ranking) has a positive impact on an individual\n",
    "                                therefore a high false negative rate will have a<font color='red'> <b>negative impact </b></font> on an individual or group.\n",
    "                                '''\n",
    "            elif y_high_positive == False:\n",
    "                html = html + '''You have indicated that a high outcome (ranking) has a negative impact on an individual\n",
    "                                therefore a high false negative rate will have a <font color='green'><b>positive impact </b></font> on an individual or group.\n",
    "                                '''\n",
    "            widgHTML = widgets.GridBox(children=[widgets.HTML(html)],\n",
    "                        layout=Layout(\n",
    "                        width='90%',\n",
    "                        )\n",
    "                   )      \n",
    "            display (widgHTML)\n",
    "            fig1, (ax1) = plt.subplots(nrows=1, figsize=(10 ,5));\n",
    "            ax1 = aeq_Plot.plot_group_metric(cross_tab,'fnr', ax1);\n",
    "            plt.tight_layout();\n",
    "            ax1.set_title('False Negative ratios');\n",
    "            plt.show()\n",
    "            plt.close(fig1);\n",
    "            plt.clf();\n",
    "            \n",
    "        with out4:#ALL metrics\n",
    "            clear_output(wait = True)\n",
    "            \n",
    "            if  y_high_positive == True:\n",
    "                html =  '''You have indicated that a <b>high outcome(ranking)</b> has a<font color='green'> <b>positive impact</b></font> on an individual.\n",
    "                                '''\n",
    "            elif y_high_positive == False:\n",
    "                html =  '''You have indicated that a <b>high outcome(ranking)</b> has a <font color='red'></b>negative impact</b></font> on an individual.\n",
    "                               '''\n",
    "            display (HTML(html))\n",
    "            def show_any(choose_measure):\n",
    "                fig1, (ax1) = plt.subplots(nrows=1);\n",
    "                ax1 = aeq_Plot.plot_group_metric(cross_tab, choose_measure, ax1)\n",
    "                plt.tight_layout()\n",
    "                ax1.set_title(choose_measure)\n",
    "                plt.show()\n",
    "                plt.close(fig1)\n",
    "                plt.clf()\n",
    "            interact(show_any, choose_measure = _choose_measure);\n",
    "   \n",
    "        with out5: #Disparate \n",
    "            clear_output(wait = True)\n",
    "            dict_of_controls = {}\n",
    "            \n",
    "            dis_imp_html = '''<b>Disparate Impact:</b> A decision-making process suffers from disparate impact if the outcome \n",
    "            of the decision disproportionately benefits one group or disproportionately hurts another group.\n",
    "            It generally results from unintentional discrimination in decision-making systems.\n",
    "            Disparities are calculated as a ratio of a metric for a group of interest compared to a reference group. \n",
    "            For example, the False Negative Rate Disparity for Group-A compared to a reference Group-B is: FNR-B/FNR-A\n",
    "            The calculated disparities are in relation to a reference group, which will always \n",
    "            have a disparity of 1.0. Disparate impact is often measured by the eighty percent or four-fifths rule. '''\n",
    "            \n",
    "            widgHTML = widgets.GridBox(children=[widgets.HTML(dis_imp_html)],\n",
    "                        layout=Layout(\n",
    "                        width='90%',\n",
    "                        )\n",
    "                   )  \n",
    "            display (widgHTML)\n",
    "        \n",
    "        \n",
    "            for feature in protected_attributes_list:\n",
    "                dict_of_controls[feature] = widgets.Dropdown(description = \"Reference group for \"+feature, \n",
    "                                             options = X_data_frame[feature].dropna().unique(),\n",
    "                                             value = feature_data_dict[feature]['privileged_description'],\n",
    "                                             layout = local_layout,\n",
    "                                             style = local_style)\n",
    "            \n",
    "                display(dict_of_controls[feature])\n",
    "                \n",
    "                \n",
    "            def show_disparity(button, space, choose_disparity_measure): #local method\n",
    "                _ref_groups_dict = {}   \n",
    "                for c in dict_of_controls:\n",
    "                    _ref_groups_dict[c] = str(dict_of_controls[c].value)\n",
    "                \n",
    "                disparity = aeq_Bias.get_disparity_predefined_groups(cross_tab, \n",
    "                                                                     original_df=df_aequitas,\n",
    "                                                                     ref_groups_dict=_ref_groups_dict, \n",
    "                                                                     alpha=0.05,\n",
    "                                                                     mask_significance=True); \n",
    "                num_rows = math.ceil( (len(protected_attributes_list))/2)\n",
    "                \n",
    "                fig = plt.figure(figsize=(12 ,6*num_rows))\n",
    "                plt.tight_layout()\n",
    "                ax_dict = {}\n",
    "                for x, num in zip (protected_attributes_list, range(len(protected_attributes_list))):\n",
    "                    ax_dict[x] = plt.subplot(1, 2, num+1)\n",
    "                    ax_dict[x] = aeq_Plot.plot_disparity(disparity, \n",
    "                                             group_metric=choose_disparity_measure, \n",
    "                                             attribute_name=x,\n",
    "                                             significance_alpha=0.05,\n",
    "                                             fig = fig,\n",
    "                                             ax = ax_dict[x]);\n",
    "                   \n",
    "                if  y_high_positive == True:\n",
    "                    html =   '''<b></b>You have indicated that a high outcome (ranking) has a <font color='green'><b>positive</b> </font> impact on a group or individual.\n",
    "                                <br>\n",
    "                                '''\n",
    "                elif y_high_positive == False:\n",
    "                    html = '''<b></b>You have indicated that a high outcome (ranking) has a <font color='red'><b>negative impact</b></font> on a group or individual.\n",
    "                                '''\n",
    "                display(HTML(html))\n",
    "                \n",
    "                plt.show()\n",
    "                display(HTML('''Sized based on group size, color based on disparity magnitude<br>\n",
    "                                Reference groups are displayed in grey with disparity = 1. <br>\n",
    "                                Disparities greater than 10x will show as 10x.<br>\n",
    "                                Disparities less than 0.1x will show as 0.1x.<br>\n",
    "                                Statistical siginificance(default 0.05) will show as ** on square.'''))\n",
    "                plt.close(fig1)\n",
    "                plt.clf()\n",
    "                \n",
    "                one = widgets.Output(layout={})\n",
    "                accordion1 = widgets.Accordion(children=[one])\n",
    "                accordion1.set_title(0, \"All Calculated values \")  \n",
    "                with one:\n",
    "                    pd.set_option('display.max_columns', None)\n",
    "                    display (disparity)\n",
    "                accordion1.selected_index = None\n",
    "                display(accordion1)\n",
    "                \n",
    "                \n",
    "                with out6:\n",
    "                    clear_output(wait = True)\n",
    "                    for ref in _ref_groups_dict:\n",
    "                        display(HTML(\"Reference group is \" +_ref_groups_dict[ref] + \" for \" + ref))\n",
    "                    display(HTML(\"Green bar indicates Fair.<br>Red bar indicates unfair.\"))\n",
    "                    group_val_fairness= aeq_Fairness.get_group_value_fairness(disparity)\n",
    "                    parity_detrminations = aeq_Fairness.list_parities(group_val_fairness)\n",
    "                    aeq_Plot.plot_fairness_group_all(group_val_fairness, ncols=5, metrics = \"all\")\n",
    "                    \n",
    "                    one = widgets.Output(layout={})\n",
    "                    accordion1 = widgets.Accordion(children=[one])\n",
    "                    accordion1.set_title(0, \"All Calculated values \")  \n",
    "                    with one:\n",
    "                        display (group_val_fairness[['attribute_name', 'attribute_value']+parity_detrminations])\n",
    "                    accordion1.selected_index = None\n",
    "                    display(accordion1)\n",
    "                    \n",
    "\n",
    "            interact(show_disparity, \n",
    "                     button = widgets.ToggleButton(\n",
    "                         description='Apply selected Reference group',\n",
    "                         layout = local_layout,\n",
    "                         style = local_style),\n",
    "                         space = widgets.Label('  ', layout=widgets.Layout(width='100%')),\n",
    "                     choose_disparity_measure = _choose_disparity_measure\n",
    "                     \n",
    "                     )\n",
    "\n",
    "        with out7:\n",
    "            html = '''<table class=\"wikitable\" align=\"center\" style=\"text-align:center; border:none; background:transparent;\">\n",
    "                    <tbody><tr>\n",
    "                    <td style=\"border:none;\" colspan=\"2\">\n",
    "                    </td>\n",
    "                    <td style=\"background:#eeeebb;\" colspan=\"2\"><b>True condition</b>\n",
    "                    </td></tr>\n",
    "                    <tr>\n",
    "                    <td style=\"border:none;\">\n",
    "                    </td>\n",
    "                    <td style=\"background:#dddddd;\"><a href=\"https://en.wikipedia.org/wiki/Statistical_population\" title=\"Statistical population\">Total population</a>\n",
    "                    </td>\n",
    "                    <td style=\"background:#ffffcc;\">Condition positive\n",
    "                    </td>\n",
    "                    <td style=\"background:#ddddaa;\">Condition negative\n",
    "                    </td>\n",
    "                    <td style=\"background:#eeeecc;font-size:90%;\"><a href=\"https://en.wikipedia.org/wiki/Prevalence\" title=\"Prevalence\">Prevalence</a> <span style=\"font-size:118%;white-space:nowrap;\">= <span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931;&#160;Condition positive</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Total population</span></span></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#cceecc;border-left:double silver;font-size:90%;\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Accuracy_and_precision\" title=\"Accuracy and precision\">Accuracy</a> (ACC) = <span style=\"font-size:118%;\"><span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931;&#160;True positive + &#931; True negative</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Total population</span></span></span>\n",
    "                    </td></tr>\n",
    "                    <tr>\n",
    "                    <td rowspan=\"2\" class=\"nowrap unsortable\" style=\"line-height:99%;vertical-align:middle;padding:.4em .4em .2em;background-position:50% .4em !important;min-width:0.875em;max-width:0.875em;width:0.875em;overflow:hidden;background:#bbeeee;\"><div style=\"-webkit-writing-mode: vertical-rl; -o-writing-mode: vertical-rl; -ms-writing-mode: tb-rl;writing-mode: tb-rl; writing-mode: vertical-rl; layout-flow: vertical-ideographic;display: inline-block; -ms-transform: rotate(180deg); -webkit-transform: rotate(180deg); transform: rotate(180deg);;-ms-transform: none ;padding-left:1px;text-align:center;\"><b>Predicted condition</b></div>\n",
    "                    </td>\n",
    "                    <td style=\"background:#ccffff;\">Predicted condition<br />positive\n",
    "                    </td>\n",
    "                    <td style=\"background:#ccffcc;\"><span style=\"color:#006600;\"><b><a href=\"https://en.wikipedia.org/wiki/True_positive\" class=\"mw-redirect\" title=\"True positive\">True positive</a></b></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#eedddd;\"><span style=\"color:#cc0000;\"><b><a href=\"https://en.wikipedia.org/wiki/False_positive\" class=\"mw-redirect\" title=\"False positive\">False positive</a></b>,<br /><a href=\"https://en.wikipedia.org/wiki/Type_I_error\" class=\"mw-redirect\" title=\"Type I error\">Type I error</a></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#ccffee;border-top:double silver;font-size:90%;\"><a href=\"https://en.wikipedia.org/wiki/Positive_predictive_value\" class=\"mw-redirect\" title=\"Positive predictive value\">Positive predictive value</a> (PPV), <a href=\"https://en.wikipedia.org/wiki/Precision_(information_retrieval)\" class=\"mw-redirect\" title=\"Precision (information retrieval)\">Precision</a> = <span style=\"font-size:118%;white-space:nowrap;\"><span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931; True positive</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Predicted&#160;condition&#160;positive</span></span></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#cceeff;border-top:double silver;font-size:90%;\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/False_discovery_rate\" title=\"False discovery rate\">False discovery rate</a> (FDR) = <span style=\"font-size:118%;white-space:nowrap;\"><span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931; False positive</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Predicted&#160;condition&#160;positive</span></span></span>\n",
    "                    </td></tr>\n",
    "                    <tr>\n",
    "                    <td style=\"background:#aadddd;\">Predicted condition<br />negative\n",
    "                    </td>\n",
    "                    <td style=\"background:#ffdddd;\"><span style=\"color:#cc0000;\"><b><a href=\"https://en.wikipedia.org/wiki/False_negative\" class=\"mw-redirect\" title=\"False negative\">False negative</a></b>,<br /><a href=\"https://en.wikipedia.org/wiki/Type_II_error\" class=\"mw-redirect\" title=\"Type II error\">Type II error</a></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#bbeebb;\"><span style=\"color:#006600;\"><b><a href=\"https://en.wikipedia.org/wiki/True_negative\" class=\"mw-redirect\" title=\"True negative\">True negative</a></b></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#eeddee;border-bottom:double silver;font-size:90%;\"><a href=\"https://en.wikipedia.org/wiki/False_omission_rate\" class=\"mw-redirect\" title=\"False omission rate\">False omission rate</a> (FOR) = <span style=\"font-size:118%;white-space:nowrap;\"><span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931; False negative</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Predicted&#160;condition&#160;negative</span></span></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#aaddcc;border-bottom:double silver;font-size:90%;\" colspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Negative_predictive_value\" class=\"mw-redirect\" title=\"Negative predictive value\">Negative predictive value</a> (NPV) = <span style=\"font-size:118%;white-space:nowrap;\"><span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931; True negative</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Predicted&#160;condition&#160;negative</span></span></span>\n",
    "                    </td></tr>\n",
    "                    <tr style=\"font-size:90%;\">\n",
    "                    <td style=\"border:none;vertical-align:bottom;padding:0 2px 0 0;color:#999999;\" colspan=\"2\" rowspan=\"2\">\n",
    "                    </td>\n",
    "                    <td style=\"background:#eeffcc;\"><a href=\"https://en.wikipedia.org/wiki/True_positive_rate\" class=\"mw-redirect\" title=\"True positive rate\">True positive rate</a> (TPR), <a href=\"https://en.wikipedia.org/wiki/Recall_(information_retrieval)\" class=\"mw-redirect\" title=\"Recall (information retrieval)\">Recall</a>, <a href=\"https://en.wikipedia.org/wiki/Sensitivity_(tests)\" class=\"mw-redirect\" title=\"Sensitivity (tests)\">Sensitivity</a>, probability&#160;of&#160;detection, <a href=\"https://en.wikipedia.org/wiki/Statistical_power\" class=\"mw-redirect\" title=\"Statistical power\">Power</a> <span style=\"font-size:118%;white-space:nowrap;\">= <span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931; True positive</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Condition&#160;positive</span></span></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#eeddbb;\"><a href=\"https://en.wikipedia.org/wiki/False_positive_rate\" title=\"False positive rate\">False positive rate</a> (FPR), <a href=\"https://en.wikipedia.org/wiki/Information_retrieval\" title=\"Information retrieval\"><span class=\"nowrap\">Fall-out</span></a>, probability&#160;of&#160;false&#160;alarm <span style=\"font-size:118%;white-space:nowrap;\">= <span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931; False positive</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Condition&#160;negative</span></span></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#eeeeee;\"><a href=\"https://en.wikipedia.org/wiki/Positive_likelihood_ratio\" class=\"mw-redirect\" title=\"Positive likelihood ratio\">Positive likelihood ratio</a> <span class=\"nowrap\">(LR+)</span> <span style=\"font-size:118%;white-space:nowrap;\">= <span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">TPR</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">FPR</span></span></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#dddddd;\" rowspan=\"2\"><a href=\"https://en.wikipedia.org/wiki/Diagnostic_odds_ratio\" title=\"Diagnostic odds ratio\">Diagnostic odds ratio</a> (DOR) <span style=\"font-size:118%;white-space:nowrap;\">= <span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">LR+</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">LR−</span></span></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#ddffdd;border-left:double silver;line-height:2;\" rowspan=\"2\"><a class=\"mw-selflink selflink\">F<sub>1</sub> score</a> = <span style=\"font-size:118%;white-space:nowrap;\">2 · <span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">Precision · Recall</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">Precision + Recall</span></span></span>\n",
    "                    </td></tr>\n",
    "                    <tr style=\"font-size:90%;\">\n",
    "                    <td style=\"background:#ffeecc;\"><a href=\"https://en.wikipedia.org/wiki/False_negative_rate\" class=\"mw-redirect\" title=\"False negative rate\">False negative rate</a> (FNR), Miss&#160;rate <span style=\"font-size:118%;white-space:nowrap;\">= <span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931; False negative</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Condition&#160;positive</span></span></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#ddeebb;\"><a href=\"https://en.wikipedia.org/wiki/Specificity_(tests)\" class=\"mw-redirect\" title=\"Specificity (tests)\">Specificity</a> (SPC), Selectivity, <a href=\"https://en.wikipedia.org/wiki/True_negative_rate\" class=\"mw-redirect\" title=\"True negative rate\">True negative rate</a> (TNR) <span style=\"font-size:118%;white-space:nowrap;\">= <span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">&#931; True negative</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">&#931;&#160;Condition&#160;negative</span></span></span>\n",
    "                    </td>\n",
    "                    <td style=\"background:#cccccc;\"><a href=\"https://en.wikipedia.org/wiki/Negative_likelihood_ratio\" class=\"mw-redirect\" title=\"Negative likelihood ratio\">Negative likelihood ratio</a> <span class=\"nowrap\">(LR−)</span> <span style=\"font-size:118%;white-space:nowrap;\">= <span role=\"math\" class=\"sfrac nowrap tion\" style=\"display:inline-block; vertical-align:-0.5em; font-size:85%; text-align:center;\"><span class=\"num\" style=\"display:block; line-height:1em; margin:0 0.1em;\">FNR</span><span class=\"slash visualhide\">/</span><span class=\"den\" style=\"display:block; line-height:1em; margin:0 0.1em; border-top:1px solid;\">TNR</span></span></span>\n",
    "                    </td></tr></tbody></table>'''\n",
    "            display(HTML(\"<b>Wikipedia Metrics overview</b>\"))\n",
    "            display(HTML(html))\n",
    "        gc.collect()\n",
    "\n",
    "    def visualise_RMSE_model_eval(self, y_train, y_test, y_pred_train, y_pred_test):\n",
    "        y_predictedTrain = y_pred_train\n",
    "        y_predictedTest = y_pred_test\n",
    "        y_test = y_test\n",
    "        y_train = y_train\n",
    "        '''We will be using Root mean squared error(RMSE) and Coefficient of Determination(R² score) to evaluate our model.\n",
    "        RMSE is the square root of the average of the sum of the squares of residuals. \n",
    "        The RMSE is the square root of the variance of the residuals. \n",
    "        #It indicates the absolute fit of the model to the data–how close the observed data points are to the model’s\n",
    "        #predicted values. Whereas R-squared is a relative measure of fit, RMSE is an absolute measure of fit. \n",
    "        #As the square root of a variance, RMSE can be interpreted as the standard deviation of the unexplained variance, \n",
    "        #and has the useful property of being in the same units as the response variable. \n",
    "        #Lower values of RMSE indicate better fit. \n",
    "        #RMSE is a good measure of how accurately the model predicts the response, and it is the most important criterion\n",
    "        #for fit if the main purpose of the model is prediction.\n",
    "\n",
    "        #Coefficient of Determination(R² score) - The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "        #A constant model that always predicts the expected value of y, disregarding the input features, \n",
    "        #would get a R^2 score of 0.0. #R-squared is between 0 and 1, Higher values are better because it means \n",
    "        #that more variance is explained by the model.'''\n",
    "\n",
    "        display(\"*****EVALUATING MODEL WITH TRAINING DATA:***\")\n",
    "        rmse = mean_squared_error(y_train, y_predictedTrain)\n",
    "        r2 = r2_score(y_train, y_predictedTrain)\n",
    "        display(' Root mean squared error: '+ str(rmse))\n",
    "        display(' R2 score: '+ str(r2))\n",
    "\n",
    "        display(\"*****EVALUATING MODEL WITH TEST DATA:******\")\n",
    "        rmse = mean_squared_error(y_test, y_predictedTest)\n",
    "        r2 = r2_score(y_test, y_predictedTest)\n",
    "        display(' Root mean squared error: ' + str(rmse))\n",
    "        display(' R2 score: '+ str(r2))\n",
    "\n",
    "        n_train = len(y_train)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.plot(range(n_train), y_train, label=\"train\")\n",
    "        plt.plot(range(n_train, len(y_test) + n_train), y_test, '-', label=\"test\")\n",
    "        plt.plot(range(n_train), y_predictedTrain, '--', label=\"prediction train\")\n",
    "\n",
    "        plt.plot(range(n_train, len(y_test) + n_train), y_predictedTest, '--', label=\"prediction test\")\n",
    "        plt.legend(loc=(1.01, 0))\n",
    "        plt.xlabel(\"Score\")\n",
    "        plt.ylabel(\"prediction\")\n",
    "        return plt\n",
    "        \n",
    "        \n",
    "        \n",
    "    def reload_data (self, pickle_path, data_frame_path, print_summary = True):\n",
    "    # Reload the file\n",
    "        data_summary = dill.load(open(pickle_path, \"rb\"))\n",
    "        data_frame = pd.read_csv(data_frame_path)\n",
    "        html = \"\"  \n",
    "        protected = []\n",
    "        non_protected = []\n",
    "        y_value = \"\"\n",
    "        if print_summary == True:\n",
    "            display(HTML(\"<b>Number of samples in dataset:</b> \" + str(data_frame.shape[0])))\n",
    "            display (HTML(\"<b>All columns in data frame:</b> \"+ str(data_frame.columns)))\n",
    "            display(HTML(\"<b>Target:</b> \"+ str (data_summary.y_value)))\n",
    "            if data_summary.Y_CONTINUOUS == True:\n",
    "                display(HTML(\"<b>Target type: </b>continuous\"))\n",
    "                display(HTML(\"<b>Num of unique values in target</b>: \" + str ( len(data_frame[data_summary.y_value].dropna().unique()))))\n",
    "                display(HTML(\"<b>Min:</b> \" + str (data_frame[data_summary.y_value].min())))\n",
    "                display(HTML(\"<b>Max </b>: \"+ str ( data_frame[data_summary.y_value].max())))\n",
    "            \n",
    "            if data_summary.Y_BINARY == True:\n",
    "                display(HTML(\"Output is binary\"))\n",
    "            if data_summary.HIGH_RANGE_POSITIVE == True:\n",
    "                display(HTML(\"Output in high range has positive effect\"))\n",
    "            if data_summary.HIGH_RANGE_POSITIVE == False:\n",
    "                display(HTML(\"Output in high range has negative effect\"))\n",
    "            \n",
    "            \n",
    "            \n",
    "            display(HTML(\"<h3>Summary of Data transformation per feature:</h3>\"))\n",
    "            \n",
    "            feature_data = data_summary.feature_data_dict \n",
    "\n",
    "            html = html + \"<ul>\"       \n",
    "            for feature in feature_data:#in order of target, protected, other.\n",
    "                html = html +\"<li><b>\"+feature+\"</b><br>\"\n",
    "                html = html + \"<ul>\"\n",
    "                html = html + \"<li>Type: \" + str(feature_data[feature]['type']) + \"<br>\"\n",
    "                if feature_data[feature]['target'] == True:\n",
    "                    html = html + \"<li>This is the target(y)<br>\"\n",
    "                    y_value = feature\n",
    "                elif feature_data[feature]['protected'] == True:\n",
    "                    html = html + \"<li>This is a protected feature<br>\"\n",
    "                    protected.append(feature)\n",
    "                else:\n",
    "                    non_protected.append(feature)\n",
    "                if feature_data[feature]['type'] == \"categorical\":\n",
    "                    html = html + \"<li>Original Values: \" + str(feature_data[feature]['original_values']) + \"<br>\"\n",
    "                    html = html + \"<li>Value descriptions: \" + str(feature_data[feature]['values_description']) + \"<br>\"\n",
    "                if feature_data[feature]['label_enc'] == True:\n",
    "                    html = html + \"<li>Label encoding was applied to this feature.\" + \"<br>\"\n",
    "                    html = html + \"<li>Label encoded values: \" + str(feature_data[feature]['label_enc_values']) + \"<br>\"\n",
    "                if feature_data[feature]['one_hot_enc'] == True:\n",
    "                    html = html + \"<li>One-Hot-Encoding was applied to this feature\" + \"<br>\"\n",
    "                    html = html + \"<li>The new columns are:\" + str(feature_data[feature]['one_hot_enc_cols_after']) + \"<br>\"\n",
    "                    html = html + \"<li>The original column before one-hot encoding:\" + str(feature_data[feature]['one_hot_enc_col_before']) + \"<br>\"\n",
    "                \n",
    "                if feature_data[feature]['values_merged'] == True:\n",
    "                    html = html + \"<li>Some values within the feature were merged.\" + \"<br>\"\n",
    "                    html = html + \"<li>The values before the merge were: \" + str(feature_data[feature]['before_merge_values']) + \"<br>\"\n",
    "                    html = html + \"<li>The values after the merge are: \" + str(feature_data[feature]['original_values']) + \"<br>\"\n",
    "                \n",
    "                if feature_data[feature]['scaled_using'] != \"\":\n",
    "                    html = html + \"<li>Scaled/Normalised using: \" + feature_data[feature]['scaled_using'] + \"<br>\"\n",
    "            \n",
    "                \n",
    "                html = html + \"<br>\"\n",
    "                html = html + \"</ul>\"\n",
    "            html = html + \"</ul>\"\n",
    "            display (HTML(html))\n",
    "        \n",
    "        \n",
    "        return data_frame, data_summary\n",
    "    \n",
    "    \n",
    "\n",
    "    #################################################################################################\n",
    "    # Detect outliers and return for one column in dataset.\n",
    "    # We find the z score for each of the data point in the dataset \n",
    "    # and if the z score is greater than 3 than we can classify that point as an outlier. \n",
    "    # Any point outside of \"thresh\" = 3 standard deviations would be an outlier.\n",
    "    # \n",
    "    #################################################################################################\n",
    "    def detect_outlier_and_describe(self, series, thresh = 3, data_type = \"numeric\"):\n",
    "        outliers=[]\n",
    "        threshold=thresh\n",
    "        size = series.count()\n",
    "        missing =  series.isnull().sum()\n",
    "        unique = len(series.unique())\n",
    "        pcnt_missing = missing/size *100\n",
    "        html = \"\"\n",
    "        if data_type == \"numeric\":\n",
    "            mean_1 = np.mean(series)\n",
    "            std_1 =np.std(series)\n",
    "        \n",
    "            html = \"Outlier is defind as any point outside \" + str(thresh) + \" standard deviations<br>\" \n",
    "            html = html + \"Min: \" + str(np.min(series)) + \"<br>\"\n",
    "            html = html + \"Max: \" + str( np.max(series)) + \"<br>\"\n",
    "            html = html + \"Mean: \" + str( mean_1) + \"<br>\"\n",
    "            html = html + \"Standard Deviation: \"+ str( std_1) + \"<br>\"\n",
    "            for y in series:\n",
    "                z_score= (y - mean_1)/std_1 \n",
    "                if np.abs(z_score) > threshold:\n",
    "                    outliers.append(y)\n",
    "            html = html + \"Number of outliers: \"+ str( len(outliers)) + \"<br>\"\n",
    "            html = html + \"Outliers: \"+ str(outliers) + \"<br>\"\n",
    "        \n",
    "\n",
    "         \n",
    "        html = html + \"Number of observations: \"+ str( size) + \"<br>\"\n",
    "        html = html + \"Num of unique values: \"+ str(unique) + \"<br>\"\n",
    "        html = html + \"Missing cells: \"+ str( missing) + \"<br>\"\n",
    "        html = html + \"Missing cells%: \"+ str( missing) + \"<br>\"\n",
    "        \n",
    "        \n",
    "        return html, outliers\n",
    "    \n",
    "        \n",
    "    #################################################################################################\n",
    "    #  This function will return  a Features dataframe, a Series with the Target and a list of the \n",
    "    # features that will be used to train the model. The Features dataframe may contain additional features\n",
    "    # such as the protected features(when not used for training), and tcolumns containing values before \n",
    "    # any kind of merge of the data.\n",
    "    #################################################################################################\n",
    "    \n",
    "    def get_features_and_target(self, \n",
    "                                data_frame, \n",
    "                                data_summary, \n",
    "                                include_protected,\n",
    "                                continuous_to_binary_target = False):\n",
    "\n",
    "        if include_protected == True:\n",
    "            cols = data_summary.protected_after_transform + data_summary.non_protected_after_transform\n",
    "        else:\n",
    "            cols = data_summary.non_protected_after_transform\n",
    "        \n",
    "        if data_summary.y_value in cols:\n",
    "            cols.remove(data_summary.y_value)\n",
    "        \n",
    "        if continuous_to_binary_target == True:\n",
    "            if not data_summary.y_value + \"_binary\" in list(data_frame.columns):\n",
    "                display(HTML(\"\"\"<font style='color:orange;'>You have set <b>'continuous_to_binary_target = True'</b>, but no translation from continuous to binary was detected!<br> \n",
    "                                <font style='color:black;'>If the label is a\n",
    "                                continuous number then run the helper method \n",
    "                                <b>set_decision_boundary(data_frame, data_summary)</b> \n",
    "                                to convert a binary label to a  continuous label \n",
    "                                before calling <b>get_features_and_target</b>. \n",
    "                             \"\"\"))\n",
    "                return data_frame.drop(data_summary.y_value, axis = 1), data_frame[data_summary.y_value], cols\n",
    "       \n",
    "            else:\n",
    "                return  data_frame.drop([data_summary.y_value, data_summary.y_value + \"_binary\"], axis = 1), data_frame[data_summary.y_value + \"_binary\"], cols\n",
    "        return  data_frame.drop(data_summary.y_value, axis = 1), data_frame[data_summary.y_value], cols\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def shap_analysis(self, shap_values, explainer, x, data_summary):\n",
    "        try:\n",
    "            shap.initjs()\n",
    "        except:\n",
    "            print ( 'shap.initjs() failed to load javascript')\n",
    "        \n",
    "        outOverview = widgets.Output(layout={})\n",
    "        out1 = widgets.Output(layout={})\n",
    "        out2 = widgets.Output(layout={})\n",
    "        out3 = widgets.Output(layout={})\n",
    "        out4 = widgets.Output(layout={})\n",
    "        out5 = widgets.Output(layout={})\n",
    "        tab_contents = [out1, out2, out3, out4, out5]\n",
    "        \n",
    "        children = tab_contents\n",
    "        tab = widgets.Tab(style={'description_layout':'auto', 'title_layout':'auto'})\n",
    "        tab.children = children\n",
    "        \n",
    "        tab.set_title(0, \"Summary Importance plot\")\n",
    "        tab.set_title(1, \"Importance plot\")\n",
    "        tab.set_title(2, \"Dependence plot\")\n",
    "        tab.set_title(3, \"Individual force plot\")\n",
    "        tab.set_title(4, \"Collective force plot\")\n",
    "        \n",
    "        local_layout = {'width': 'auto', 'visibility':'visible'}\n",
    "        local_layout_hidden  = {'width': 'auto', 'visibility':'hidden'}\n",
    "        local_style = {'description_width':'initial'}\n",
    "        display(outOverview)\n",
    "        display(tab)\n",
    "        \n",
    "        \n",
    " \n",
    "        _choose = widgets.Dropdown(description = \"Select Feature\", \n",
    "                                    options = list(x.columns),\n",
    "                                    layout = local_layout,\n",
    "                                    style = local_style)\n",
    "        all_comb = {}\n",
    "        for f in data_summary.protected_after_transform:\n",
    "            for a in  x[f].unique():\n",
    "                all_comb[(f+\":\"+ str(a))] = a\n",
    "        \n",
    "        _protected = widgets.Dropdown(description = \"Filter by Protected Feature\", \n",
    "                                     options = all_comb,\n",
    "                                     layout = local_layout,\n",
    "                                     style = local_style)\n",
    "        \n",
    "        toggle = widgets.ToggleButton(\n",
    "                            value=False,\n",
    "                            description='Generate',\n",
    "                            disabled=False,\n",
    "                            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                            \n",
    "                            )\n",
    "        \n",
    "        with outOverview:\n",
    "            display (HTML('''<h3>SHAP interpretability via Machnamh</h3>(SHapley Additive exPlanations) KernelExplainer is a \n",
    "            model-agnostic method which builds a weighted linear regression by using training/test data, \n",
    "            training/test predictions, and whatever function that predicts the predicted values. \n",
    "            SHAP values represent a feature's responsibility for a change in the model output.\n",
    "            It computes the variable importance values based on the Shapley values from game theory, \n",
    "            and the coefficients from a local linear regression. </br>\n",
    "            see: https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf <br>\n",
    "\n",
    "            It offer a high level of interpretability for a model, through two distinct approaches:\n",
    "\n",
    "            <br><b>Global interpretability</b> — the SHAP values can show how much each predictor contributes, \n",
    "            either positively or negatively, to the target variable. Similar to a variable importance plot however it also indicates the positive or negative relationship between each feature and the target output.\n",
    "\n",
    "            <br><b>Local interpretability</b> — each observation is assigned it's own SHAP value. \n",
    "            This provides a very granular level of transparency and interpretability where we can \n",
    "            determine why an individual cases receive a specific prediction  and the contribution of \n",
    "            each feature to the prediction. Generally speaking variable importance algorithms usually \n",
    "            only show the results across the entire dataset but not on each individual case.'''))\n",
    "            \n",
    "        with out1:\n",
    "          \n",
    "            html_desc = '''\n",
    "            <b>Summary importance plot </b><br><b>Feature importance:</b> Variables are ranked in descending order. The top variables contribute more to the model than the bottom ones and thus have high predictive power.<br>\n",
    "            ''' \n",
    "            wi1 = widgets.Output(layout=Layout(width='60%'))\n",
    "            with wi1:\n",
    "                shap.summary_plot(shap_values, x, plot_type=\"bar\"); \n",
    "            wi2 = widgets.HTML(value=html_desc,layout=Layout(width='30%') ) ; \n",
    "            sidebyside = widgets.HBox([wi1, wi2])\n",
    "            display (sidebyside)\n",
    "        with out2:\n",
    "            display (HTML('''<b>Importance plot:</b> lists the most significant variables in descending order. \n",
    "                          The top variables contribute more to the model than the bottom ones and thus have high predictive power.'''))\n",
    "            html_desc = '''\n",
    "            <b>Feature importance:</b> Variables are ranked in descending order.<br>\n",
    "            <b>Impact:</b> Horizontal location indicates if effect of feature is associated with a higher or lower prediction.<br>\n",
    "            <b>Original value:</b> Colour indicates if feature variable is high(red) or low(blue) for the particular observation.<br>\n",
    "            <b>Correlation:</b> A high or low impact(indicated by colour), a positive or negative impact(indicated by position on x-axis)\n",
    "                '''  \n",
    "            wi1 = widgets.Output(layout={})\n",
    "            with wi1:\n",
    "                shap.summary_plot(shap_values, x);\n",
    "            wi2 = widgets.HTML(value=html_desc,layout=Layout(width='30%') )  \n",
    "            sidebyside = widgets.HBox([wi1, wi2])\n",
    "            display (sidebyside)\n",
    "                \n",
    "        with out3:\n",
    "            \n",
    "            display (HTML (\"The decision variable is \" + str(data_summary.y_value)))\n",
    "            display (HTML ('''To understand how a single feature effects the output of the model a \n",
    "                             dependency plot plots the SHAP value of  that feature vs. the value of \n",
    "                             the feature for all the examples in a dataset.'''))\n",
    "            def show_dependancy_plot(choose):\n",
    "                html_desc = '''The dependency plots show relationship between the target ('''+ data_summary.y_value +  ''') \n",
    "                   and the selected feature ('''+ choose + ''') to review if it is linear, monotonic or \n",
    "                  more complex.  The additionla variable is the variable that the selected feature (''' + choose + ''') \n",
    "                  interacts with the most frequently. Vertical dispersion at a single value represents interaction \n",
    "                  effects with the other features.  '''\n",
    "                display (HTML(html_desc))\n",
    "                display (shap.dependence_plot(choose, shap_values, x))\n",
    "            interact(show_dependancy_plot, choose = _choose);\n",
    "    \n",
    "        with out4:\n",
    "            display (HTML (\"The decision variable is \" + str(data_summary.y_value)))\n",
    "            display (HTML ('''<b>Individual Force plot</b> shows the features which each contribute to push the model output \n",
    "                            from the base value (the average model output over the dataset passed) to the\n",
    "                            model output. Features pushing the prediction higher are shown in red, \n",
    "                            those pushing the prediction lower are shown in blue.'''))\n",
    "            # visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "            display (HTML (\"<b>Generate random sample to investigate:</b>\"))\n",
    "            def show_individual_force_plot(protected, toggle):\n",
    "                feat = _protected.label.split(':')[0]\n",
    "                index = x[x[feat] == _protected.value].sample(1).index[0]\n",
    "                display (shap.force_plot(explainer.expected_value, \n",
    "                                     shap_values[index,:], \n",
    "                                     x.iloc[index,:],\n",
    "                                     matplotlib=True))\n",
    "            \n",
    "            interact(show_individual_force_plot, protected = _protected, toggle = toggle);\n",
    "         \n",
    "        with out5:\n",
    "            display (HTML (\"The decision variable is \" + str(data_summary.y_value)))\n",
    "            display (HTML ('''<b>Collective Force plot</b> A combination of all individual force plots, each rotated 90 degrees, and stacked\n",
    "                                horizontally, to explanation an entire dataset.'''))\n",
    "            display (shap.force_plot(explainer.expected_value, \n",
    "                                     shap_values, \n",
    "                                     x))\n",
    "\n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def get_protected (self, summary):\n",
    "        return summary.protected_before_transform\n",
    "\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    #def get_protected_before_merge (self, summary):\n",
    "    #    return summary.all_columns_in_x\n",
    "    #   print (list([all_columns_in_x.contains('_bm')]))\n",
    "    #   print (list(X_train.columns[X_train.columns.str.contains('_benc')]))\n",
    "\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    #def get_protected_before_transform (self, summary):\n",
    "    #    all_cols = summary.all_columns_in_x\n",
    "    #    prot = summary.protected_x\n",
    "\n",
    "    #    new_prot = []\n",
    "    #    for f in prot:\n",
    "    #        found = False\n",
    "    #        if f+'_bm' in all_cols:\n",
    "    #           new_prot.append(f+'_bm')\n",
    "    #           found = True\n",
    "    #       if f+'_benc' in all_cols:\n",
    "    #           new_prot.append(f+'_benc')\n",
    "    #            found = True\n",
    "    #        if f.endswith('_oh_benc'):\n",
    "    #            new_prot.append(f)\n",
    "    #            found = True\n",
    "    #    \n",
    "    #        if found == False:\n",
    "    #            new_prot.append(f)\n",
    "    #    return new_prot\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def serialise_ranked_list(self, X, y, y_prob_actual, y_prob_1, y_pred, save_to_path = './', name = \"\"):\n",
    "        \n",
    "        ranked_dict = {}\n",
    "        ranked_dict['X'] = X\n",
    "        ranked_dict['y'] = y\n",
    "        ranked_dict['y_prob_actual'] = y_prob_actual\n",
    "        ranked_dict[ 'y_prob_1'] =  y_prob_1\n",
    "        ranked_dict['y_pred'] =  y_pred\n",
    "        path =  save_to_path + name + \"_ranked_data.pickle\"\n",
    "        dill.dump(ranked_dict, file = open(path, \"wb\"))\n",
    "        display (HTML(\"Serialised data to dictionary 'ranked_dict', at \" + path))\n",
    "        return path\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def reload_ranked_list (self, _path):\n",
    "        path = _path\n",
    "        ranked_dict = dill.load(open(path, \"rb\"))\n",
    "        X = ranked_dict['X']\n",
    "        y = ranked_dict['y'] \n",
    "        y_prob_actual = ranked_dict['y_prob_actual']\n",
    "        y_prob_1 = ranked_dict[ 'y_prob_1']\n",
    "        y_pred = ranked_dict['y_pred']\n",
    "        return  X, y, y_prob_actual, y_prob_1, y_pred\n",
    "\n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def run_shap_and_serialise_response(self, X_in, \n",
    "                                       model_predict,\n",
    "                                       count = 100, \n",
    "                                       save_to_path = './'):\n",
    "        x = shap.sample( X_in, count)\n",
    "        x = x.reset_index(drop=True)\n",
    "        explainer = shap.KernelExplainer(model_predict, x ) # The second argument is the \"background\" dataset; a size of 100 rows is gently encouraged by the code\n",
    "        shap_values = explainer.shap_values(x, l1_reg=\"num_features(10)\")\n",
    "        print(f'length of SHAP values: {len(shap_values)}')\n",
    "        print(f'Shape of each element: {shap_values[0].shape}')\n",
    "        path =  save_to_path + \"shap_values.pickle\"\n",
    "        print (\"Shap_values saved to\", path)\n",
    "        dill.dump(shap_values, file = open(path, \"wb\"))\n",
    "        path =  save_to_path + \"shap_explainer.pickle\"\n",
    "        print (\"Shap_explainer saved to\", path)\n",
    "        dill.dump(explainer, file = open(path, \"wb\"))\n",
    "        path =  save_to_path +\"shap_x.pickle\"\n",
    "        print (\"Shap_explainer saved to\", path)\n",
    "        dill.dump(x, file = open(path, \"wb\"))\n",
    "        display (HTML (\"The model-agnostic SHAP explainer <b>'KernelExplainer'</b> has been used.\"))\n",
    "        return explainer, shap_values, x\n",
    "\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def reload_shap_data (self, _path):\n",
    "        path = _path \n",
    "        shap_values_path = path + \"/shap_values.pickle\"\n",
    "        explainer_path = path + \"/shap_explainer.pickle\"\n",
    "        x_path = path + \"/shap_x.pickle\"\n",
    "        shap_values = dill.load(open(shap_values_path, \"rb\"))\n",
    "        explainer = dill.load(open(explainer_path, \"rb\"))\n",
    "        x = dill.load(open(x_path, \"rb\"))\n",
    "        # Reload the file\n",
    "        return shap_values, explainer, x\n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def get_features_type(self, df, unique_max):\n",
    "        numeric_cat = []\n",
    "        obj = []\n",
    "        cat = []\n",
    "        boo = []\n",
    "        #pandas data types.\n",
    "        # datetime64 - currently not supported by the tool\n",
    "        # timedelta[ns] - currently not supported by the tool\n",
    "        # object\n",
    "        # int64\n",
    "        # float64\n",
    "        # bool\n",
    "        # category\n",
    "        \n",
    "        for col in df.select_dtypes(include='number').columns:\n",
    "            if len(df[col].dropna().unique()) <= unique_max:\n",
    "                numeric_cat.append(col)\n",
    "                \n",
    "        for col in df.select_dtypes(include='object').columns:\n",
    "            if len(df[col].dropna().unique()) <= unique_max:\n",
    "                obj.append(col)\n",
    "                \n",
    "        for col in df.select_dtypes(include='category').columns:\n",
    "            if len(df[col].dropna().unique()) <= unique_max:\n",
    "                cat.append(col)\n",
    "                \n",
    "        for col in df.select_dtypes(include='bool').columns:\n",
    "            if len(df[col].dropna().unique()) <= unique_max:\n",
    "                boo.append(col)\n",
    "\n",
    "        all_categorical = cat + obj + numeric_cat + boo\n",
    "        all_numeric = list (df.columns)\n",
    "        all_numeric = [ele for ele in all_numeric if ele not in all_categorical] \n",
    "        return all_categorical, all_numeric\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def get_feature_info (self, feature, unique_values, group_descriptions_dict, label_encoding_dict, oh_encoding_dict, merged_dict, trace = False):\n",
    "        values = unique_values\n",
    "        decoded_values = []\n",
    "        original_values = []\n",
    "        label_encoded_values = []\n",
    "        \n",
    "        keys = []\n",
    "        \n",
    "        if feature in oh_encoding_dict:\n",
    "            original_feature_bohe = oh_encoding_dict[feature][\"Original_col\"]\n",
    "            original_value_bohe = oh_encoding_dict[feature][\"Original_val\"]\n",
    "            if trace == True:\n",
    "                print (\"One Hot Encoded from feature:\", original_feature_bohe, \"value:\",original_value_bohe)\n",
    "                print (\"One Hot Encoded values:\", values)\n",
    "            _choice_dict_for_drop = dict(zip(values, values))\n",
    "            original_values = values\n",
    "            label_encoded_values = []\n",
    "            descriptions = values\n",
    "            return _choice_dict_for_drop, original_values, label_encoded_values, descriptions\n",
    "            \n",
    "        def get_key(val): #local method in get_feature_info\n",
    "            for key, value in label_encoding_dict[feature].items(): \n",
    "                if val == value: \n",
    "                    return key \n",
    "            return None\n",
    "        \n",
    "        #if feature is already encoded then unique_values will be the encoded versions\n",
    "        #If feature does not have a description saved then return {x:x, y:y etc} as\n",
    "        #the key value pairs for any dropdown. regardless of encoded or not.\n",
    "        if feature not in group_descriptions_dict:\n",
    "            original_values = values \n",
    "            if feature in label_encoding_dict:\n",
    "                for value in values:\n",
    "                    decoded_values.append(get_key(value))\n",
    "                    original_values = decoded_values\n",
    "                    label_encoded_values = values \n",
    "                descriptions = original_values\n",
    "                _choice_dict_for_drop = dict(zip(original_values, label_encoded_values))\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                _choice_dict_for_drop = dict(zip(values, values))\n",
    "                descriptions = values\n",
    "            \n",
    "            if trace == True:\n",
    "                print (\"Original values \", original_values)\n",
    "                print (\"Label Encoded values \", label_encoded_values )\n",
    "                print (\"Description \",  descriptions )\n",
    "                print (\"Key/Value for dropdown: \", _choice_dict_for_drop)\n",
    "            \n",
    "            return _choice_dict_for_drop, original_values, label_encoded_values, descriptions\n",
    "        \n",
    "        \n",
    "        if feature in group_descriptions_dict:\n",
    "            #first check if the input feature unique_values are the result of an Encode\n",
    "            if feature in label_encoding_dict:\n",
    "                for value in values:\n",
    "                    decoded_values.append(get_key(value))\n",
    "                original_values = decoded_values\n",
    "                label_encoded_values = values\n",
    "                if trace == True:\n",
    "                    print (\"Original values \", original_values)\n",
    "                    print (\"Label Encoded values \", label_encoded_values )\n",
    "             \n",
    "            if feature not in label_encoding_dict:\n",
    "                original_values = values\n",
    "                label_encoded_values = []\n",
    "                if trace == True:\n",
    "                    print (\"Original values \", original_values)\n",
    "                    print (\"Label Encoded values \", label_encoded_values )\n",
    "                \n",
    "            for key in original_values:\n",
    "                if key not in group_descriptions_dict[feature]:\n",
    "                    keys.append(key)\n",
    "                else:\n",
    "                    keys.append(group_descriptions_dict[feature][key])\n",
    "        # using zip() \n",
    "        # to convert lists to dictionary \n",
    "            _choice_dict_for_drop = dict(zip(keys,values))\n",
    "            descriptions = keys\n",
    "            if trace == True:\n",
    "                print (\"Description: \", keys)\n",
    "                print (\"Key/Value for dropdown: \", _choice_dict_for_drop)\n",
    "                if feature in merged_dict:\n",
    "                    print (\"Merged Values: \", merged_dict[feature])\n",
    "        return _choice_dict_for_drop, original_values, label_encoded_values, descriptions\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def phi_k_correlation(self, df):\n",
    "        intcols = []\n",
    "        selcols = []\n",
    "        for col in df.columns.tolist():\n",
    "            try:\n",
    "                tmp = (\n",
    "                        df[col]\n",
    "                        .value_counts(dropna=False)\n",
    "                        .reset_index()\n",
    "                        .dropna()\n",
    "                        .set_index(\"index\")\n",
    "                        .iloc[:, 0]\n",
    "                    )\n",
    "                if tmp.index.inferred_type == \"mixed\":\n",
    "                    continue\n",
    "\n",
    "                if pd.api.types.is_numeric_dtype(df[col]):\n",
    "                    intcols.append(col)\n",
    "                    selcols.append(col)\n",
    "                elif df[col].nunique() <= config[\n",
    "                    \"categorical_maximum_correlation_distinct\"\n",
    "                ].get(int):\n",
    "                    selcols.append(col)\n",
    "            except (TypeError, ValueError):\n",
    "                continue\n",
    "\n",
    "        if len(selcols) > 1:\n",
    "            correlation = df[selcols].phik_matrix(interval_cols=intcols)\n",
    "\n",
    "            return correlation\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    #################################################################################################\n",
    "    #  \n",
    "    # \n",
    "    #################################################################################################\n",
    "    def Benfords_law(self, df, feature, protected):\n",
    "        groups = df[protected].dropna().unique()\n",
    "        tab = widgets.Tab()\n",
    "        widget_arr = {}\n",
    "        tab_titles = []\n",
    "        fit_output = widgets.Output(layout={})       \n",
    "                    \n",
    "        for group in groups:\n",
    "            filtered = df[df[protected]==group]\n",
    "            X = filtered[feature].values\n",
    "            # # Make fit\n",
    "            with fit_output:\n",
    "                out = bl.fit(X)\n",
    "            # # Plot\n",
    "            widget_arr[group] = widgets.Output(layout={})\n",
    "            with widget_arr[group]:\n",
    "                display(bl.plot(out,\n",
    "                        title='Benfords law for '+ str(feature) + ' and group '+ str(group),  \n",
    "                        figsize=(8,4)));\n",
    "            tab_titles.append(str(group))\n",
    "        widget_arr[\"Output\"] = fit_output\n",
    "        tab.children = list(widget_arr.values())\n",
    "        \n",
    "        for x in range(len(tab_titles)):\n",
    "            tab.set_title(x, tab_titles[x])\n",
    "        tab.set_title(x+1,\"Output Trace\")\n",
    "        return tab\n",
    "    \n",
    "    \n",
    "    def de_hot_encode_feature (self, df, original_col, hot_encoded_cols):\n",
    "        num_chars = len(original_col) + 1\n",
    "        df[original_col] = 0\n",
    "        for col in hot_encoded_cols:\n",
    "            map_to = col[num_chars:]\n",
    "            df.loc[df[col] == 1, original_col] = map_to\n",
    "\n",
    "        return df[original_col]\n",
    "\n",
    "\n",
    "    def map_values (self, data_frame, protected_attributes_list, feature_data_dict):\n",
    "        for feat in protected_attributes_list:\n",
    "            #create a dictionary out of two lists..\n",
    "            if feature_data_dict[feat]['values_merged'] == True:\n",
    "                display (\"the feature was merged\")\n",
    "                display (\"column before merge is \", feature_data_dict[feat]['before_merge_col'])\n",
    "                #data_frame[feat] = data_frame['before_merge_col']\n",
    "\n",
    "            if feature_data_dict[feat]['one_hot_enc'] == True:\n",
    "                #One_hot was applied\n",
    "                original_col = feature_data_dict[feat]['one_hot_enc_col_before']\n",
    "                hot_encoded_cols = feature_data_dict[feat]['one_hot_enc_cols_after']\n",
    "                data_frame[feat] = self.de_hot_encode_feature(data_frame, original_col, hot_encoded_cols)\n",
    "\n",
    "                #now if there are descriptions use the descriptions\n",
    "                if len(feature_data_dict[feat]['values_description']) != 0:\n",
    "                    map_dictionary = dict(zip(feature_data_dict[feat]['original_values'], \n",
    "                                              feature_data_dict[feat]['values_description']))\n",
    "                    data_frame[feat] = data_frame[feat].map(map_dictionary)\n",
    "\n",
    "\n",
    "            elif feature_data_dict[feat]['label_enc'] == True:\n",
    "                #Label encoding was applied\n",
    "                #if there are descriptions use the descriptions otherwise use the non-label encoded values\n",
    "                if len(feature_data_dict[feat]['values_description']) != 0:\n",
    "                    map_dictionary = dict(zip(feature_data_dict[feat]['label_enc_values'], \n",
    "                                          feature_data_dict[feat]['values_description']))\n",
    "                else:\n",
    "                    map_dictionary = dict(zip(feature_data_dict[feat]['label_enc_values'], \n",
    "                                          feature_data_dict[feat]['original_values']))\n",
    "                data_frame[feat] = data_frame[feat].map(map_dictionary)\n",
    "\n",
    "\n",
    "            else:\n",
    "                #No encoding was applied\n",
    "                if len(feature_data_dict[feat]['values_description']) != 0:\n",
    "                    map_dictionary = dict(zip(feature_data_dict[feat]['original_values'], \n",
    "                                              feature_data_dict[feat]['values_description']))\n",
    "                    data_frame[feat] = data_frame[feat].map(map_dictionary)\n",
    "\n",
    "\n",
    "        return data_frame[protected_attributes_list]\n",
    "    \n",
    "    #################################################################################################\n",
    "    #  copied from Medium article, will use it as a\n",
    "    # \n",
    "    #################################################################################################\n",
    "    def make_confusion_matrix(self, \n",
    "                              conf_matrix, \n",
    "                              feature,\n",
    "                              group_names=None,\n",
    "                              categories='auto',\n",
    "                              count=True,\n",
    "                              percent=True,\n",
    "                              cbar=True,\n",
    "                              xyticks=True,\n",
    "                              xyplotlabels=True,\n",
    "                              sum_stats=True,\n",
    "                              figsize=None,\n",
    "                              cmap='Blues',\n",
    "                              title=None):\n",
    "        \n",
    "        cm_all = conf_matrix.copy()\n",
    "        '''\n",
    "        This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
    "        Arguments\n",
    "        ---------\n",
    "        conf_matrix:   Aequitas entire confusion matrix to be passed in\n",
    "        feature        The protected feature to view\n",
    "        group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
    "        categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
    "        count:         If True, show the raw number in the confusion matrix. Default is True.\n",
    "        normalize:     If True, show the proportions for each category. Default is True.\n",
    "        cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
    "                       Default is True.\n",
    "        xyticks:       If True, show x and y ticks. Default is True.\n",
    "        xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
    "        sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
    "        figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
    "        cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
    "                       See http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "\n",
    "        title:         Title for the heatmap. Default is None.\n",
    "        '''\n",
    "        \n",
    "        out_dict = {} \n",
    "       \n",
    "        cm_all = cm_all[cm_all['attribute_name'] == feature] \n",
    "        groups = cm_all['attribute_value'].unique()\n",
    "        for group in groups:\n",
    "            cm_group = cm_all[cm_all['attribute_value'] == group].squeeze() #squeese changes it to series\n",
    "            tn = cm_group['tn']\n",
    "            fp = cm_group['fp']\n",
    "            fn = cm_group['fn']\n",
    "            tp = cm_group['tp']\n",
    "\n",
    "            cf =  np.array([[tn,  fp],\n",
    "                  [ fn, tp]])\n",
    "            \n",
    "            out_dict[group] = widgets.Output(layout = {'border': 'solid 1px white', 'padding': '25px'})\n",
    "\n",
    "            # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
    "            blanks = ['' for i in range(cf.size)]\n",
    "\n",
    "            if group_names and len(group_names)==cf.size:\n",
    "                group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
    "            else:\n",
    "                group_labels = blanks\n",
    "\n",
    "            if count:\n",
    "                group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
    "            else:\n",
    "                group_counts = blanks\n",
    "\n",
    "            if percent:\n",
    "                group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
    "            else:\n",
    "                group_percentages = blanks\n",
    "\n",
    "            box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
    "            box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
    "\n",
    "\n",
    "            # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
    "            if sum_stats:\n",
    "                #Accuracy is sum of diagonal divided by total observations\n",
    "                accuracy  = np.trace(cf) / float(np.sum(cf))\n",
    "\n",
    "                #if it is a binary confusion matrix, show some more stats\n",
    "                if len(cf)==2:\n",
    "                    #Metrics for Binary Confusion Matrices\n",
    "                    precision = cf[1,1] / sum(cf[:,1])\n",
    "                    recall    = cf[1,1] / sum(cf[1,:])\n",
    "                    f1_score  = 2*precision*recall / (precision + recall)\n",
    "                    stats_text = \"\"\"\\n\\nAccuracy={:0.3f}\n",
    "                                      \\nPrecision/Positive predictive value(PPV)={:0.3f}\n",
    "                                      \\nRecall/True Positive Rate/Sensitivity={:0.3f}\n",
    "                                      \\nF1 Score={:0.3f}\"\"\".format(\n",
    "                        accuracy,precision,recall,f1_score)\n",
    "                    html = '<font style=\"font-family:sans-serif; font-size:10px;color:black;\">'\n",
    "                    html = html + \"Accuracy: \" + str(round(accuracy,2)) + \"<br>\"\n",
    "                    html = html + \"Precision/Positive predictive value(PPV): \" + str(round(precision,2)) + \"<br>\"\n",
    "                    html = html + \"Recall/True Positive Rate/Sensitivity: \" + str(round(recall,2)) + \"<br>\"\n",
    "                    html = html + \"F1 Score=: \" + str(round(f1_score,2)) + \"<br>\"\n",
    "                          \n",
    "                else:\n",
    "                    stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
    "            else:\n",
    "                stats_text = \"\"\n",
    "\n",
    "            stats_text = ''#Going to use the HTML instead\n",
    "            # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
    "            if figsize==None:\n",
    "                #Get default figure size if not set\n",
    "                figsize = plt.rcParams.get('figure.figsize')\n",
    "\n",
    "            if xyticks==False:\n",
    "                #Do not show categories if xyticks is False\n",
    "                categories=False\n",
    "\n",
    "\n",
    "            # MAKE THE HEATMAP VISUALIZATION\n",
    "            plt.figure(figsize=figsize)\n",
    "            sns.heatmap(cf,annot=box_labels,\n",
    "                        fmt=\"\",\n",
    "                        cmap=cmap,\n",
    "                        cbar=cbar,\n",
    "                        xticklabels=categories,\n",
    "                        yticklabels=categories\n",
    "                       )\n",
    "\n",
    "            if xyplotlabels:\n",
    "                plt.ylabel('True label')\n",
    "                plt.xlabel('Predicted label' + stats_text)\n",
    "            else:\n",
    "                plt.xlabel(stats_text)\n",
    "\n",
    "            if title:\n",
    "                plt.title(title)\n",
    "            with out_dict[group]:\n",
    "                display(HTML(group))\n",
    "                plt.show()\n",
    "                display(HTML(html))\n",
    "                \n",
    "        l = list(out_dict.values())\n",
    "        n = 3\n",
    "        outList = []\n",
    "        for i in range(n, len(l) + n, n):\n",
    "            outList.append(l[i-n:i])\n",
    "\n",
    "        for chunk_of_3 in outList:\n",
    "            display (widgets.HBox([*chunk_of_3], layout = Layout(\n",
    "                                                            padding = '10px',\n",
    "                                                            width='100%',\n",
    "                                                            display='flex',\n",
    "                                                            align_items='stretch',\n",
    "                                                            align_content='space-between',\n",
    "                                                            )\n",
    "                                 ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "30",
    "lenType": "30",
    "lenVar": "200"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
